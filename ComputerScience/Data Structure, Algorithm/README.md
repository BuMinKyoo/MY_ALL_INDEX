<br/> 

###### Top

- [알고리듬이란, 효율성](#알고리듬이란-효율성)
- [기초 자료 구조와 시간 복잡도](#기초-자료-구조와-시간-복잡도)
- [재귀함수, 꼬리재귀함수](#재귀함수-꼬리재귀함수)
- [주먹구구식 알고리듬, P vs NP 문제](#주먹구구식-알고리듬-p-vs-np-문제)
- [탐색 알고리듬, 이진 탐색](#탐색-알고리듬-이진-탐색)
- [정렬 알고리듬(버블,선택,삽입,퀵,병합,힙)](#정렬-알고리듬버블선택삽입퀵병합힙)
- [해시 알고리듬](#해시-알고리듬)
- [암호화](#암호화)

<br/>
  
- [트리](#트리)
- [이진 탐색 트리](#이진-탐색-트리)
- [트리 순회(tree traversal)](#트리-순회tree-traversal)
- [레드-블랙 트리(red-black tree)](#레드블랙-트리redblack-tree)
- [트라이(Trie), 공간분할 트리](#트라이trie-공간분할-트리)
- [깊이 우선 탐색, 너비 우선 탐색, 미니맥스](#깊이-우선-탐색-너비-우선-탐색-미니맥스)
- [동적 계획법](#동적-계획법)
- [그리디(greedy, 탐욕) 알고리듬](#그리디greedy-탐욕-알고리듬)

<br/>

- [그래프](#그래프)
- [그래프 깊이 우선 탐색(DFS)](#그래프-깊이-우선-탐색dfs)
- [그래프 너비우선 탐색(BFS), 최단경로](#그래프-너비우선-탐색bfs-최단경로)
- [그래프 알고리즘 다른것들](#그래프-알고리즘-다른것들)

<br/>
<br/>

***

# 알고리듬이란, 효율성
  - 알고리듬이란?
    - 어떤 부류의 문제를 해결하는 컴퓨터로 구현 가능한 명백한 명령어들
    - 간단한 문제를 해결하는것도 전부 알고리듬이라고 할 수 있다!
    - 따라서 우리가 작성하는 거의 모든 코드는 알고리듬 이라고 할 수 있음
    - 하지만 사소한 코드는 보통 학계 및 실무에서 알고리듬이라 부르지 않음
    - 무엇을 알고리듬이라 하고 무엇을 아니라 하는지 명백한 기준은 없음
    - 사람들이 말하는 습관을 보고 익숙해져야 할 부분

<br/>

  - 훌륭한 알고리듬이 갖춰야할 자질
    - 입력과 출력이 명확히 정의되어 있어야 함
      - 입력은 시작 시 비어있을 수도 있음
    - 알고리듬의 각 단계가 명확하며 모호하지 않아야 함
    - 유한 시간 안에 결과가 나와야 함
    - 포팅이 가능한 의사코드 작성하기
      - 거의 모든 언어에 공통되는 연산만 사용하기
      - 결국 하드웨어와 기계어/어셈블리어 수준에서 지원하는 것들
      - 고수준 언어 중에는 C에서 지원하는 것 정도
      - 특정 언어에 있는 추상적으로 만들어진 것으로 알고리듬을 구현하면 보통 좋지 않다
  - 알고리듬 공부를 해도 안 느는 프로그래머들
    - 하드웨어가 어떤 연산을 지원하는지 모름
    - 이미 존재하는 마법 같은 함수만 호출해봄
    - 툭하면 언어 문법이 틀리는데 컴파일 오류를 봐도 그 문제를 못 찾음
    - 컴퓨터에 데이터가 어떻게 저장되는지 모름
    - 힙과 스택 메모리의 차이에 대해 모름
  - 알고리듬의 효율성
    - 자원의 효율적 사용을 뜻함
    - 자원
      - 시간 : CPU 속도 등
      - 공간/용량 : 메모리 사용량 등
    - 시간과 공간은 종종 상반 관계
    - 자원을 많이 사용할수록 그 알고리듬이 복잡하다고 말함
      - 시간 복잡도
      - 공간 복잡도
      - 알고리듬 복잡도를 표현하는 방법 중 하나 : 빅오 표기법
  - 알고리듬의 효율성 분석은 다소 추상적
    - 알고리듬 공부를 할 때는 하드웨어 차이에 신경을 안씀
      - 추상적인 기계에서 알고리듬을 실행한다 가정
        - 왜냐하면, 요즘 컴퓨터는 덧셈이 숫자가 커도 한번에 연산이 가능하지만, 예를들어 한번에 1씩 밖에 더하지 못하는 기계에서는 알고리듬 속도가 전혀 달라질 수 있기 때문에
      - 알고리듬 자체에 집중하도록 도와줌
    - 랜덤 접근 기계
      - 다양한 하드웨어를 일반적인 형태로 대표하는 가상의 기계
      - 레지스터를 갖춘 CPU 1개
      - 정수와 부동소수점 저장 가능
      - 메모리 간접 참조 지원
      - 캐시 메모리나 가상 메모리 등은 없음
  - 주의 : 알고리듬의 효율성과 실제 성능
    - 실제 코드 실행 속도는 하드웨어 따라 매우 달라질 수 있음
    - 따라서 실무에서는 효율성 낮은 알고리듬이 더 빠르기도 함
      - 실무에서는 현재 사용하고 있는 실제 하드웨어에서의 성능을 측정할것
    - 공부법
      - 알고리듬 공부를 통해 이론상의 성능에 대해 확실히 습득할 것
      - 하드웨어에 따라 달라지는 부분은 추가 지식으로 늘려나가면 됨

<br/>

  - 점근 표기법과 빅오 표기법
    - 점근 표기법(asymptotic notation)
      - 정수론과 해석학의 방법
      - 어떤 함수가 증가하는 모습을 다른 함수와 비교
      - 알고리듬의 복잡도를 논하거나 단순화시킬 때 사용
      - 대표적인 표기법
        - 대문자 O표기법(빅오 표기법)
          - 컴퓨터 공학에서는 주로 빅오 표기법을 사용함
        - 소문자 o 표기법
        - 대문자 오메가 표기법
        - 소문자 오메가 표기법
        - 대문자 세타 표기법
    - 빅오 표기법
      - 이름에서 알 수 있듯이 대문자 O를 이용해 표기
      - 주로 알고리듬을 분류하기 위해 사용
        - O(1), O(log n), O(n), O(nlog n), O(n²), O(n!)
    - 어떤 기준으로 분류 하는지?
      - 입력 데이터가 많아 짐에 따라 다음 둘이 얼마나 늘어나는지 측정
        - 실행시간(시간 복잡도)
        - 필요한 공간(공간 복잡도)

<br/>

  - O(1) 알고리듬
    - 입력 데이터의 크기 N에 상관없이 언제나 일정한 시간이 걸림
  - O(n) 알고리듬
    - 입력 데이터의 크기 N에 비례하는 시간이 걸림
  - O(n²) 알고리듬
    - 입력 데이터 크기 N의 제곱에 비례하는 시간이 걸림
  - O(log n) 알고리듬
    - O(1) 과 O(n) 사이
    - log는 2씩 곱해 나가는 것에 반대라고 생각하면 된다, 즉 분할 알고리즘 같은것 ^^
  - O(nlog n) 알고리듬
    - O(n) 과 O(n²) 사이

<br/>

  - ‘대략 그 정도’의 의미
    - 알고리듬의 실행 시간을 일반화하여 표현해서 쉽게 분류
      - 실행 시간 : 실행해야 하는 코드 단계 수
      - 실행 시간의 예 : 5n² - 5n + 3
      - 분류의 예 : O(n²) 알고리듬
    - 이 때 실행 시간 증가에 가장 큰 영향을 미치는 항만 사용해 일반화
      - 최고차항
    - 최고 차항에 붙은 계수도 무시

<br/>

  - 최선 vs 평균 vs 최악
    - 데이터에 따라 실제 알고리듬의 실행 속도가 달라질 수 있음
    - 데이터가 앞에 있냐 뒤에 있냐에 따라서 속도는 달라질 수 있음
    - 일반적으로 평균 시간을 시간 복잡도로 사용
  - O(1) < O(log n) < O(n) < O(nlog n) < O(n²) < O(2ⁿ) < O(n!)

###### [알고리듬이란, 효율성](#알고리듬이란-효율성)
###### [Top](#top)

<br/>
<br/>

***

# 기초 자료 구조와 시간 복잡도
  - 기초 자료 구조와 시간 복잡도(공간 복잡도는 다 O(n)이 된다)
    - 배열
      - 복잡도
        - 삽입 : 평균 O(N), 최악 O(N)
        - 삭제 : 평균 O(N), 최악 O(N)
        - 검색 : 평균 O(N), 최악 O(N)
    - 스택
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(1)
        - 삭제 : 평균 O(1), 최악 O(1)
        - 검색 : 평균 O(N), 최악 O(N)
    - 큐
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(1)
        - 삭제 : 평균 O(1), 최악 O(1)
        - 검색 : 평균 O(N), 최악 O(N)
    - 연결리스트
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(1)
        - 삭제 : 평균 O(1), 최악 O(1)
        - 검색 : 평균 O(N), 최악 O(N)
    - HashMap, Map, Dictionary
      - Key 와 Value 의 쌍으로 데이터를 저장하는 자료구조
    - Hashtable
      - Key를 Hash function에 집어 넣고, 그것을 배열의 고유한 index를 생성하고, 이 index를 활용해 값을 저장하거나 검색한다.
      - Value는 그 index에 해당하는 bucket, 즉 배열에 들어간다
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(N)
        - 삭제 : 평균 O(1), 최악 O(N)
        - 검색 : 평균 O(1), 최악 O(N)
    - 트리
    - 그래프

###### [기초 자료 구조와 시간 복잡도](#기초-자료-구조와-시간-복잡도)
###### [Top](#top)

<br/>
<br/>

***

# 재귀함수, 꼬리재귀함수
  - 재귀함수
    - 큰 문제를 반복 적용 가능한 작은 문제로 나뉘 푸는 방법
    - 어떤 함수가 매개변수만 바꾸어 자기 스스로를 호출하는 방식으로 구헌
  - 재귀함수의 장점
    - 가독성이 좋음
    - 코드가 짧음
    - 각 단계의 변수 상태가 자동 저장됨
    - 코드 검증도 쉬움
  - 재귀함수의 단점
    - 재귀적 문제 분석/설계가 안 직관적
    - 맹목적인 믿음이 필요
    - 스택 오버플로 발생 가능
    - 함수 호출에 따른 과부하

<br/>

  - 기본적으로 재귀 함수를 사용하는 게 나은 방법
    - 가독성이 좋고 유지보수가 쉬운 코드가 더 중요
  - 다음과 같을 경우 반복문으로 변환
    - 스택 오버플로가 날 가능성이 있는 경우
    - 성능 문제가 일어날 가능성이 큰 경우
    - 성능 문제가 확인된 경우
  - 모든 재귀 함수는 반복문으로 작성 가능
    - 복잡한 경우 스택 등의 데이터 구조를 사용해야 함

<br/>

  - 꼬리 호출(tail call)
    - 함수 코드 제일 마지막에서 다른 함수를 호출하는 경우
    - 그 후에 실행하는 명령어가 없음
  - 스택 프레임이 존재하는 이유
    - 함수에서 사용 중인 변수 값을 유지하기 위해
    - 타 함수 호출 후 반환되면 스택에 저장했던 값을 되돌려 사용
  - 꼬리 호출의 경우는 타 함수로부터 반환 후 더 이상 연산이 없음
    - 곧 바로 호출자로 반환
  - 따라서 스택 프레임에 저장해 놓은 변수 값을 재사용하지 않음
    - 이런 경우 컴파일러가 스택 프레임을 따라 안 만들고, 그냥 함수를 2개 따로 호출하는 것으로 만들기도 한다

<br/>

#ConsoleApp.cpp
~~~c#
public int sum()
{
  … 
  
  return sumsum();
}
~~~

<br/>

  - 꼬리 재귀(tail recursion)
    - 꼬리 호출의 특수한 경우
    - 마지막에 호출하는 함수가 자기 자신
    - 꼬리 호출과 똑같은 최적화가 적용됨

<br/>

#ConsoleApp.cpp
~~~c++
// 일반 재귀 함수
#include <iostream>

int factorialRecursive(int n)
{
    if (n <= 1)
        return 1;

    return n * factorialRecursive(n - 1);
}


int main()
{
    int n = factorialRecursive(4);
    std::cout << n << std::endl;
}
~~~

<br/>

#ConsoleApp.cpp
~~~c++
// 꼬리 재귀 함수
#include <iostream>

int factorialRecursive(int n, int fac)
{
    if (n <= 1)
        return fac;

    return factorialRecursive(n - 1, n * fac);
}

int factorial(int n)
{
	return factorialRecursive(n, 1);
}

int main()
{
    int n = factorial(4);
    std::cout << n << std::endl;
}
~~~

<br/>

  - 꼬리 재귀 함수 작성하기
    - 보통 꼬리 재귀 함수가 덜 직관적
    - 그러나 이런 식으로 작성된 코드가 종종 보임
    - 가장 큰 이유는 앞에서 말했던 최적화
    - 하지만 꼬리 호출 최적화를 지원 안 하는 언어라면?
      - 안 돼도 충분한 의미가 있음
      - 꼬리 재귀는 반복문으로 쉽게 변경 가능
    - 일반 재귀 함수보다 꼬리 재귀 함수가 더 좋은 이유
      - 일반 재귀 함수일 경우 재귀 할 때마다 메모리 스택에 함수 실행을 위해 할당하게 되고 이를 반복하게 되서 더이상 메모리 스택에 할당할 수 없을 때 스택 오버 플로우 등의 문제가 발생하는걸 방지할 수 있다
        - 재귀 할 때마다 이전 함수에서 할당한 메모리를 반납하기 때문
      - 꼬리 재귀 함수인지 판단하는 방법으로 함수 실행이 끝날 때 할당된 메모리가 없다면 꼬리 재귀고, 여전히 메모리를 할당받고 있다면 꼬리 재귀가 아닌 일반 재귀로 생각할 수 있다
    - 보통 debug모드에서는 TCO최적화를 해주지 않기 때문에 할 수 없지만, release모드 및 최적화 옵션을 최대로 키면 컴파일러가 해주기 때문에 확인 할 수 있다.
      - 언어 단에서 지원하지 않을 수도 있음

<br/>

#ConsoleApp.cpp
~~~c++
#include <iostream>

// 일반 재귀
int SumRecursive(int n)
{
    if (n <= 1)
        return n;

    return n + SumRecursive(n - 1);
}

// 꼬리 재귀
int SumRecursiveTail(int n, int fac)
{
    if (n <= 1)
        return n + fac;

    return SumRecursiveTail(n - 1, n + fac);
}
int Sum(int n)
{
	return SumRecursiveTail(n, 0);
}


int main()
{
    int n = SumRecursive(100000); // 스택오버 플로우가 발생함

    int n2 = Sum(100000); // 스택오버 플로우가 발생하지 않음

    std::cout << n << std::endl;
    std::cout << n2 << std::endl;
}
~~~

###### [재귀함수, 꼬리재귀함수](#재귀함수-꼬리재귀함수)
###### [Top](#top)

<br/>
<br/>

***

# 주먹구구식 알고리듬, P vs NP 문제
  - 주먹구구식(brute-force) 알고리듬
    - 모든 가능한 경우의 수를 시도하는 알고리듬
    - 좋은 알고리듬의 조건 중 ‘효율성’을 고려하지 않은 알고리듬
    - 보통 가장 직관적인 문제 해결법
    - 간단한 주먹구구식 알고리듬의 예
      - 배열에서 어떤 값의 첫 번째/마지막 색인 찾기
      - 배열에 들어있는 정수들의 합 또는 평균 구하기
      - 배열에서 최솟값이나 최댓값 찾기
      - char[ ]에 저장된 문자열 뒤집기(사본 생성 금지)
      - 등 등
    - 주먹구구식 알고리듬과 시간 복잡도
      - O(N) 보다 시간 복잡도가 높은 알고리듬들이 많음
      - 컴퓨터에서 실행하기에는 너무 느린 알고리듬들도 많음
        - 알려진 최적화 방법이 없는 것들도 존재
        - 반드시 나쁜 일은 아님
        - 보안 분야가 이에 많이 의존

<br/>

  - P vs NP 문제
    - 학문적으로 꽤 재밌는 논의가 있었던 부분
    - 아직까지 풀리지 않은 미해결 수학 문제 7개 중 하나
풀리면 21세기 사회에 가장 크게 공헌할 수 있는 문제 중 하나
  - P분류(P class)
    - 판정 문제들을 분류하는 방법 중 하나
      - 판정 문제 : 입력 값에 대해 예/아니오 답을 내릴 수 있는 문제
    - 결정론적 튜링 기계에서 다항식 시간 안에 풀 수 있는 모든 문제를 포함
    - 결정론적 튜링 기계
      - 튜링 기계 : 무언가를 계산하는 기계를 대표하는 가상의 장치
        - 일반적인 컴퓨터 알고리듬을 수행할 수 있음
      - 결정론적 튜링 기계란?
        - 어떤 명령어 실행 뒤, 다음 실행할 명령어가 확정됨
        - 코어 하나에서 명령어를 순서대로 실행한다 생각할 것
        - 즉, 코어 하나에서 실행되는 다항식 시간 알고리듬이 있는 문제는 P
  - NP분류(NP class)
    - NP : 비결정적 다항식 시간
      - Not P가 아님!!!, P와 NP는 반대적이나 이런게 아님
    - 비결정론적 튜링 기계
      - 어떤 명령어 실행 뒤, 다음 실행할 명령어가 확정되지 않음
      - 여러 개의 다음 명령어를 병렬적으로 실행하는 기계

<br/>

  - 결정론적 튜링 기계에서의 NP문제
    - 일단 답이 있으면 그 답이 맞는지를 다항식 시간안에 검증할 수 있음
    - 푸는 데는 지수 시간이 걸릴 수도 있음

<br/>

  - 랜덤 접근 기계는 결정론적 튜링 기계(요즘 컴퓨터도 이와 같다!)
    - 랜덤 접근 기계 : 레지스터를 갖춘 CPU1개
    - 결정론적 튜링 기계
      - 어떤 명령어 실행 즉시, 다음 실행할 명령어가 확정됨
      - 코어 하나에서 명령어를 순서대로 실행한다 생각할 것
    - 앞으로 별도 언급이 없으면 결정론적 튜링 기계를 의미
      - NP문제를 일반적인 방법으로 풀기에는 좀 느림

<br/>

  - P문제는 결정론적 튜링 기계에서 다항식 시간 안에 풀 수 있는 모든 문제를 포함
  - NP문제는
    - 비결정론적 튜링 기계에서 해법을 다항식 시간안에 찾을 수 있는것
    - 결정론적 튜링 기계에서 일단 답이 있으면 그 답이 맞는지를 다항식 시간안에 검증할 수 있음
    - P가 풀 수 있는문제이기 때문에는 P문제라면, NP문제라고 할 수 있다

<br/>

  - NP-완전(NP-complete, NPC) 문제
    - NP문제중 일부
    - 모든 NP문제들은 NP-완전 문제로 환원 가능
      - 그것도 다항식 시간 안에
      - 여전히 NP문제이니 다항식 시간안에 답 검증 가능
    - 최소 다른 NP문제들만큼 어려운 문제
    - 따라서 NP중에서도 가장 어려운 문제라고 할 수 있음
  - NP-난해(NP-hard) 문제
    - 최소 NP-완전 문제만큼 어려운 문제들
    - NP가 아닌 문제도 있음
      - 즉, 다항식 시간 안에 답 검증이 불가능한 문제
      - 당연히 NP보다 복잡도가 높은 문제

<br/>

  - P = NP vs P != NP
    - NP-완전 문제는 NP 문제 중 가장 어려운 문제
    - NP-완전 문제 중 하나라도 다항식 시간 안에 풀 수 있다면?
      - 이 문제는 P가 됨
      - 모든 NP문제를 NP-완전 문제로 다항식 시간 안에 환원할 수 있음
      - 따라서 모든 NP 문제가 P가 됨(P = NP)
    - P = NP가 되면 디지털 사회에 미치는 여파는?
      - 느려서 못 풀던 그 많은 문제를 효율적으로 풀 수 있음

###### [주먹구구식 알고리듬, P vs NP 문제](#주먹구구식-알고리듬-p-vs-np-문제)
###### [Top](#top)

<br/>
<br/>

***

# 탐색 알고리듬, 이진 탐색
  - 탐색 알고리듬
    - 어떤 데이터 구조 안에 저장되어 있는 정보를 구해오는 알고리듬
    - 매우 다양한 것이 여기에 포함됨
      - 배열에서 제일 큰 값 찾기
      - 데이터베이스에서 레코드 하나 읽어오기
      - 배낭 문제
      - 등
    - 대표적인 탐색 알고리듬
      - 선형(linear) 탐색 알고리듬 O(N)
      - 해시 맵을 이용한 탐색 O(1)
  - 이진 탐색 알고리듬
    - 정렬된 배열에서 어떤 값의 위치를 찾는 알고리듬
    - 한 단계 진행할 때마다 탐색범위를 절반으로 줄임
      - 이진 이라는 이름이 탄생한 이유
    - 분할 정복 알고리듬 중 하나
      - 정복이라 하기에는 모든 문제 영역을 방문하지 않음
    - 재귀 함수로 쉽게 작성 가능
  - 정렬된 데이터와 알고리듬
    - 정렬된 데이터에 사용할 수 있는 효율적인 알고리듬이 많음
    - 정렬되지 않은 배열은?
      - 정렬 알고리듬을 사용하여 정렬 가능
      - 일단 정렬하면 효율적 알고리듬 사용 가능
      - 하지만 배열에 새 요소를 추가하면 다시 정렬해야 함
        - 배보다 배꼽이 커질 수도 있음
       - 정렬 알고리듬이 이진 탐색보다 시간 복잡도가 높음
  - 정렬 후 이진 탐색 vs 선형 탐색
    - 배열이 안 바뀌고, 같은 배열을 탐색할 일이 많다면 정렬후 이진탐색으로
    - 배열이 자주 바뀌는 경우는 정렬 하지 않고 선형 탐색으로

<br/>

#ConsoleApp.cpp
~~~c++
#include <iostream>

// 이진 탐색
int binarySearch(int* arr, int start, int end, int target)
{
    if (start <= end)
    {
        int mid = start + (end - start) / 2;

        if (arr[mid] == target)
            return mid;
        else if (arr[mid] > target)
            return binarySearch(arr, start, mid - 1, target);
        else
            return binarySearch(arr, mid + 1, end, target);
    }

    return -1;
}

int main()
{
    int num[] = { 0,1,2,3,4,5,6,7,8,9,10 };

    int n = binarySearch(num, 0, 10, -1);
    std::cout << n << std::endl;
}
~~~

###### [탐색 알고리듬, 이진 탐색](#탐색-알고리듬-이진-탐색)
###### [Top](#top)

<br/>
<br/>

***

# 정렬 알고리듬(버블,선택,삽입,퀵,병합,힙)
  - 목록 안에 저장된 요소들을 특정한 순서대로 재배치하는 알고리듬
  - 정렬을 하는 이유
    - 좀 더 효율적인 알고리듬을 사용하기 위해
    - 사람이 읽기 편하도록
    - 등
  - 입력 데이터는 일반적으로 배열 같은 데이터 구조에 저장
    - 아무 위치로의 임의 접근을 허용
    - 연결 리스트를 사용하면 처음 혹은 끝부터 차례대로 훑어야 함
  - 흔히 사용하는 순서 : 숫자 순서, 사전 순서
  - 정렬 방향 : 오름차순, 내림차순
  - 다양한 정렬 알고리듬이 있음
    - 시간 복잡도 차이
    - 메모리 사용량 차이
    - 안정성 차이
      - 안전성(safety)이 아님!
      - 똑같은 키(key)를 가진 데이터들의 순서가 바뀌지 않느냐 여부
    - 직렬 vs 병렬 차이

<br/>

  - 안정성을 잘 모르는 이유
    - 같은 키를 가진 데이터의 순서가 바뀌어도 문제가 아닌 경우가 보통
    - 그래서 잘 모르고 생각도 안 하는 부분
    - 심지어는 이렇게 잘못 생각하기도 함
      - 모든 정렬 알고리듬은 같은 키를 가진 데이터의 순서를 안 바꾼다
    - 이 때문에 버그가 나도 못 고치는 경우가 있음
    - 진실
      - 어떤 정렬 알고리듬은 안정성을 보장
      - 어떤 정렬 알고리듬은 보장 안 함
  - 안정성이 문제가 되는 경우
    - 1. 정렬의 기준이 되는 정렬 키(sort key)와 실제 데이터가 다름
    - 2. 구조체/클래스의 일부 멤버만 정렬 키로 사용

<br/>

  - 대표적인 정렬 알고리듬
    - 버블 정렬
      - 언제라도 구현할 수 있어야 함
    - 선택 정렬
      - 언제라도 구현할 수 있어야 함
    - 퀵 정렬
      - 언제라도 설명할 수 있어야 함
    - 병합 정렬
      - 이해하는 정도면 충분
    - 힙 정렬
      - 이해하는 정도면 충분
    - 삽입 정렬
  - 정렬 알고리듬은 아무리 빨라도…
    - 배열을 비교/정렬하려면 모든 요소를 최소 한 번씩은 방문해야 함
    - 배열의 모든 요소를 방문하는 것은 O(N)
    - 따라서 정렬 알고리듬은 아무리 빨라도 O(N)보다 느림
    - 흔히 보는 시간 복잡도 중 O(N)다음으로 느린 것은? : NlogN
  - 정렬 알고리듬 비교
    - 퀵의 경우는 스택 메모리를 사용하기 때문에 메모리 할당과 해체가 공짜로 일어난다. 그래서 병합,힙 알고리듬보다 더 빠르다. 퀵은 거의 O(1)으로 돌아간다고 생각할 수 있다

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/d5c3a20f-c4aa-4648-8b3b-a8142471c479)

<br/>

  - 상황에 따른 정렬 알고리듬 선택
    - 기본적인 상황 : 퀵 정렬
      - C도 qsort()함수를 기본 제공
    - 간단히 구현할 때 : 버블 정렬
      - 구현이 매우 쉬움
      - 10년 안써도 까먹을 수 없을 정도
    - 어떤 경우에도 느려지면 안 될 때 : 병합 또는 힙 정렬
      - 평균은 퀵 정렬 보다 느림
      - 최악의 경우 여전히 O(N log N)
    - 특수한 상황에 적합한 정렬 알고리듬도 존재
      - 예 :  기수(radix)정렬

<br/>

  - 버블(bubble) 정렬
    - 가장 간단한 알고리듬 중 하나
      - 기본기 중의 기본기
      - 스스로 이 알고리듬을 고안하지 못해도 됨
      - 하지만 한 번 이해하면 언제라도 작성 가능해야 함
    - 이웃 요소 둘을 비교해서 올바른 순서로 고치는 과정을 반복
    - 한번 목록을 순회할 때마다 가장 큰 값이 제일 위로 올라가
      - 기포가 수면으로 떠오르는 모습을 닮았다고 해서 버블 정렬
      - 큰 기포일수록 수면으로 더 빨리 떠오름
    - 버블 정렬의 시간 복잡도
      - N - 1회(N : 요소 수)
    - 버블 정렬의 공간 복잡도
      - 새로 만든 목록이 없기 때문에 O(1)
    - 버블 정렬의 안정성
      - 값이 같은 경우 순서를 바꾸지 않음, 따라서 정렬 후에도 순서가 유지가 되기 때문에, 안정성 : O

<br/>

#ConsoleApp.cpp
~~~c++
#include <iostream>

int main()
{
    int array[] = { 10, 9, 8, 4, 5, 3, 7, 1, 2, 6 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	for (int i = 0; i < arraySize - 1; i++)
	{
		for (int j = 0; j < arraySize - i - 1; j++)
		{
			if (array[j] > array[j + 1])
			{
				int temp = array[j];
				array[j] = array[j + 1];
				array[j + 1] = temp;
			}
		}
	}

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 선택(selection) 정렬
    - 역시 가장 간단한 정렬 알고리듬 중 하나
    - 목록을 총 N-1번 훑으면서 다음 과정을 반복
      - 첫 번째는 요소0부터 훑으면서 최솟값을 찾아 요소 0과 교환
      - 두 번째는 요소1부터 훑으면서 최솟값을 찾아 요소 1과 교환
      - 세 번째는 요소2부터 훑으면서 최솟값을 찾아 요소 2과 교환
      - N-1 번째까지 반복…
    - 최솟값을 찾아 선택한다고 해서 선택 정렬
    - 시간/공간 복잡도 : 버블 정렬과 동일
    - 안정성 : 보장 안됨
      - 예) 같은 3이라는 숫자가 4번째 인덱스 7번째 인덱스에 있지만, 정렬을 하면서 7번째에 있는 인덱스 3숫자가 4번째 인덱스 보다 작은 인덱스로 이동하게 될 수도 있다

#ConsoleApp.cpp
~~~c++
#include <iostream>

int main()
{
	// 최소값으로 정렬하기
    int array[] = { 10, 9, 8, 4, 5, 3, 7, 1, 2, 6 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	int inMinIndex = 0;
	for (int i = 0; i < arraySize - 1; i++)
	{
		inMinIndex = i;

		for (int j = i + 1; j < arraySize; j++)
		{
			if (array[j] < array[inMinIndex])
			{
				inMinIndex = j;
			}
		}

		// 최소값과 현재 위치의 값을 교환
		int temp = array[i];
		array[i] = array[inMinIndex];
		array[inMinIndex] = temp;
	}

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 삽입(insertion)정렬
    - 역시 간단한 정렬 알고리듬 중 하나
    - 버블 정렬, 선택 정렬보다 구현은 아주 조금 힘듦
    - 목록을 차례대로 훑으로면서 다음 과정을 반복
      - 현재 위치의 요소를 뽑음
      - 이걸 과거에 방문했던 요소들 중에 어디 사이에 넣어야 정렬이 유지되는지 판단
      - 그 위치에 삽입
      - 삽입으로 인해 다른 요소들을 오른쪽으로 밀어야(shift) 할 수도 있음
    - 외부 반복문의 반복 횟수는 고정
      - 모든 요소를 방문함
      - 정해진 횟수기 때문에 for문이 적합
    - 내부 반복문의 반복 횟수는 가변적
      - 필요한 만큼까지만 오른쪽으로 미는 방식
      - 정해지지 않은 횟수이니 while문이 더 적합
    - 시간/공간 복잡도 : 버블 정렬과 동일
    - 안정성 : 보장 됨

#ConsoleApp.cpp
~~~c++
#include <iostream>

int main()
{
	// 최소값으로 정렬하기
    int array[] = { 10, 9, 8, 4, 5, 3, 7, 1, 2, 6 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	for (int i = 1; i < arraySize; i++)
	{
		int key = array[i];
		int j = i - 1;

		while (j >= 0 && array[j] > key)
		{
			int temp = array[j];
			array[j] = array[j + 1];
			array[j + 1] = temp;

			j--;
		}
	}

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 퀵(quick) 정렬
    - 실무에서 가장 많이 사용하는 정렬
      - 일반적/범용적으로 가장 빠름
    - 진정한 분할 정복 알고리듬
      - 모든 요소를 방문함
      - 복잡도에 log가 있다는 것에서 눈치챌 수 있음
    - 어떤 값(pivot)을 기준으로 목록을 하위 목록으로 2개로 나눔
      - 목록을 나누는 기준은 pivot보다 작냐/크냐
      - 이 과정을 재귀적으로 반복
      - 재귀 단계가 깊어질 때마다 새로운 pivot 값을 뽑음
    - 퀵 정렬의 시간 복잡도
      - 각 단계마다 방문하는 요소 수 : O(N)
      - 총 몇 개의 단계?
        - 매 단계에서 좌우가 균등하게 나뉘면
          - O(log N)
        - 매 단계 모든 요소가 한쪽으로 몰리면
          - O(N)
      - 평균 : O(N log N)
      - 최악 : O(N²)
    - 최악의 상황 피하기?
      - 제일 끝이 아닌 다른 위치를 기준값으로 뽑음
      - 기준값 위치의 예
        - 왼쪽
        - 오른쪽
        - (왼쪽 + 오른쪽) / 2
      - 어느 경우에도 최악의 상황은 있음
    - O(N²)을 절대로 허용할 수 없다면?
      - 다른 정렬을 사용할 것
      - 평균 속도 vs 최악의 상황 사이의 균형
    - 여러가지 분할법
      - 왼쪽-> 오른쪽 : 로무토 분할법
      - 왼쪽-> 오른쪽, 오른쪽 -> 왼쪽 번갈아 진행 : 호어 분할법
        - 어떤 값을 기준값으로 선택해도 잘 작동
        - 하지만 중간 값을 피벗으로 사용하면 더 빠르게 만들 수있다
    - 퀵 정렬의 공간 복잡도
      - 재귀적으로 함수를 호출
      - 실제 원본 배열을 고침 : O(1)
      - 함수 호출 깊이만큼 스택 메모리 사용
        - O(log N)
        - 스택 메모리라 할당/해제가 매우 빠름
      - 한 함수 내에서 재귀 함수를 두번 호출
       - 두 번째 호출은 꼬리 재귀를 통해 피할 수 있음

<br/>

#ConsoleApp.cpp
~~~c++
// 로무토 분할법
// 피봇값이 맨 오른쪽
#include <iostream>

void quicksort(int nums[], int left, int right)
{
	if (left >= right)
	{
		return;
	}

	int pivot = right;
	int basePoint = left;

	for (int i = left; i < right; i++)
	{
		if (nums[pivot] > nums[i])
		{
			int temp = nums[i];
			nums[i] = nums[basePoint];
			nums[basePoint] = temp;
			basePoint++;
		}
	}

	int temp = nums[pivot];
	nums[pivot] = nums[basePoint];
	nums[basePoint] = temp;
	pivot = basePoint;

	quicksort(nums, left, pivot - 1);
	quicksort(nums, pivot + 1, right);
}

void quickLomuto(int arr[], int size)
{
	quicksort(arr, 0, size - 1);
}


int main()
{
	// 최소값으로 정렬하기
    int array[] = { 6, 2, 8, 3, 1, 4, 9, 5, 7, 0 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	// 정렬하기
	quickLomuto(array, arraySize);

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

#ConsoleApp.cpp
~~~c++
//호어 분할법
// 피봇값이 맨 왼쪽
#include <iostream>

void quicksort(int arr[], int start, int end)
{
	if (start >= end)
		return;

	int pivot = start;
	int low = start + 1;
	int high = end;

	while (low <= high)
	{
		while (arr[pivot] >= arr[low] && low <= end)
		{
			low++;
		}

		while (arr[pivot] <= arr[high] && high >= (start + 1))
		{
			high--;
		}

		if (low < high)
		{
			int temp = arr[low];
			arr[low] = arr[high];
			arr[high] = temp;
		}
	}

	int temp2 = arr[high];
	arr[high] = arr[pivot];
	arr[pivot] = temp2;
	pivot = high;

	quicksort(arr, start, pivot - 1);
	quicksort(arr, pivot + 1, end);
}


void quickHoare(int arr[], int size)
{
	quicksort(arr, 0, size - 1);
}


int main()
{
	// 최소값으로 정렬하기
    int array[] = { 6, 2, 8, 3, 1, 4, 9, 5, 7, 0 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	// 정렬하기
	quickHoare(array, arraySize);

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

~~~c++
//호어 분할법
// 피봇값이 맨 왼쪽
// 피봇값이 중간값을 이용한 속도 개선
#include <iostream>

void quicksort(int arr[], int start, int end)
{
	if (start >= end)
		return;

	////////
	int samples[3] = { start, (start + end) / 2, end };

	if (arr[samples[0]] > arr[samples[1]])
	{
		int temp = samples[0];
		samples[0] = samples[1];
		samples[1] = temp;
	}
	if (arr[samples[1]] > arr[samples[2]]) {

		int temp = samples[1];
		samples[1] = samples[2];
		samples[2] = temp;
	}
	if (arr[samples[0]] > arr[samples[1]]) {

		int temp = samples[0];
		samples[0] = samples[1];
		samples[1] = temp;
	}

	int temp3 = arr[samples[1]];
	arr[samples[1]] = arr[start];
	arr[start] = temp3;
	////////

	int pivot = start;
	int low = start + 1;
	int high = end;

	while (low <= high)
	{
		while (arr[pivot] >= arr[low] && low <= end)
		{
			low++;
		}

		while (arr[pivot] <= arr[high] && high >= (start + 1))
		{
			high--;
		}

		if (low < high)
		{
			int temp = arr[low];
			arr[low] = arr[high];
			arr[high] = temp;
		}
	}

	int temp2 = arr[high];
	arr[high] = arr[pivot];
	arr[pivot] = temp2;
	pivot = high;

	quicksort(arr, start, pivot - 1);
	quicksort(arr, pivot + 1, end);
}

void quickHoare(int arr[], int size)
{
	quicksort(arr, 0, size - 1);
}

int main()
{
	int array[] = { 8, 2, 4, 1, 3, 10, 1, 1, 6, 5 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	// 정렬하기
	quickHoare(array, arraySize);

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 병합(merge)정렬
    - 1. 입력 배열을 재귀적으로 반씩 나눠 요소수가 1인 배열들을 만듦
      - 요소수가 1이니 정렬된 배열
      - 정확히 반씩 나누니 재귀 깊이는 O(log N)
    - 2. 재귀 반대 방향으로 배열을 계속 합침
      - 이때 정렬된 상태를 유지해야 함
      - 각 재귀 단계마다 방문하는 요소수는 O(N)
    - 3. 제일 상위 단계까지 합치면 정렬 끝

<br/>

  - 병합정렬 예제 추가하기

<br/>

  - 힙(heap) 정렬
    - 힙은 트리(tree)에 기반한 자료 구조
      - 우선순위 큐의 효율적인 구현 방법 중 하나
    - 힙 정렬은 힙이 사용하는 정렬 알고리듬
      - 언제나 부모의 키가 자식의 키와 같거나 큼
      - 이 자료구조에 데이터를 저장하는 순간 정렬이 됨
      - 즉, 정렬 안 된 데이터를 힙에 한 번 넣었다 빼면 끝
<br/>

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/dee80b15-187f-4ca6-841f-99569e9c4912)

  - 힙정렬 예제 추가하기

###### [정렬 알고리듬(버블,선택,삽입,퀵,병합,힙)](#정렬-알고리듬버블선택삽입퀵병합힙)
###### [Top](#top)

<br/>
<br/>

***

# 해시 알고리듬
  - 다양한 해시 알고리듬의 용도
    - 해시(hash)는 컴퓨터 공학에서 매우 근본이 되는 알고리듬 중 하나
      - 해시 테이블에서 데이터를 저장할 위치를 찾기 위해
      - 길이가 긴 데이터 둘을 빨리 비교하기 위해
      - 누출되면 곤란한 데이터의 원본을 저장하지 않기 위해
  - 해시 함수의 정의
    - 임의의 크기를 가진 값을 고정 크기의 값에 대응시키는 함수
      - 임의 크기 -> 고정크기가 된다
    - 여전히 함수이므로 수학에서의 함수의 정의도 만족해야 함
      - 어떤 입력값에 어떤 출력값이 나옴(출력 값이 2개가 나올수 없고, 입력값이 똑같은것이 들어가면 출력 값이 똑같은 것이 나온다)
  - 해시 알고리듬 분류
    - (비 암호학적) 해시 함수
      - 체크섬
      - 순환 중복 검사
      - 등
    - 암호학적 해시 함수

<br/>

  - 해시 알고리듬 속성
    - 효율성
    - 보통 빠른 해시 함수를 선호함
    - 공간을 더 낭비해도 빠른 접근 속도를 선호
    - 충돌이 좀 더 나더라도 더 빠른 함수를 선호
      - 충돌은 드문 일
      - 몇개 난다고 O(1)에서 크게 느려지지 않음
    - 하드웨어 가속이 어려운 해시를 선호하는 경우도 있음
      - 여전히 소프트웨어에서는 빨리 실행되는 걸 선호
    - 균일성
    - 해시 함수의 출력값이 고르게 분포될수록 균일성이 높음
    - 흔히 훌륭한 해시 함수는 균일성이 높아야 한다고 함
      - 출력 범위 안의 모든 값들이 동일한 확률로 나와야 함(균등 분포)
      - 이러면 해시 충돌이 적어 O(1)해시 테이블을 기대할 수 있음
    - 완벽한 해시 함수 : 해시 충돌이 전혀 없는 함수
      - 입력값이 매우 제한적일 경우에만 가능
    - 균일성의 측정
      - 카이제곱 검정을 이용
      - 결과가 0.95~1.05 사이면 균일한 분포를 가진 해시 함수라 봄
      - 해시 값이 덜 중복되게 버킷 수를 정하면 균일성을 높일 수 있음(소수를 사용)
      - 완벽한 눈사태가 나도록 해시 함수를 설계하면 균일성을 높일 수 있다
        - 눈사태 효과 : 입력값이 약간만 바뀌어도 출력값이 굉장히 많이 바뀌는것, 엄격한 눈사태 기준은 입력값에서 1비트를 뒤집으면 출력값의 각 비트가 뒤집힐 확률이 50%가 되는것
    - 균일성이 높다고 항상 좋은 것이 아니라 다 쓰임세가 있음
      - 비슷한 내용을 가진 데이터끼리 충돌하게 함
      - 엄청나게 많은 데이터에서 비슷한 것들을 찾는 용도

<br/>

  - 비암호학적 해시 함수
    - 암호학적으로 사용하기에 안전하지 않은 해시 함수들
    - 보안적으로 문제없는 용도에 주로 사용
      - 데이터 저장 및 찾기
      - 저장/전송 중에 생긴 데이터 오류 탐지
      - 고유한 ID 생성
      - 등
    - 절대 반지는 없다
      - 모든 데이터에 대해 최고의 결과를 보장하는 해시 함수는 존재하지 않음
      - 입력값에 따라 다른 해시 함수를 사용하는 확률적 알고리듬은 존재
        - 유니버설 해싱
      - 따라서 용도에 맞는 해시 함수를 사용하는 게 중요
      - 심지어는 비트 패킹도 해시 함수로 사용 가능
    - 체크섬(checksum)
      - 비암호학적 해시
      - 여러 데이터로부터 도출한 작은 크기의 데이터 하나
        - 보통 데이터에 있는 모든 바이트를 어떤 방식으로든 합함
      - 해시 함수랑 매우 비슷한 개념
        - 출력값의 크기가 고정되어 있으면 해시 함수
      - 용도 : 저장 혹은 전송 중에 발생한 오류를 찾아냄
        - 처음 데이터를 저장할 때 체크섬을 계산해 그것도 저장
        - 나중에 데이터를 읽을 때 다시 체크섬을 계산
        - 처음에 저장해둔 체크섬과 다르면 오류가 난것
      - 예시 : 주민등록 번호 유효성 검사
        - 존재할 수 있는 번호인지 검사
        - 마지막 숫자는 어떠한 공식에 따라서 계산하여 표기한다
        - 이러한 방법으로 체크섬을 사용한다
      - 예시 : 신용카드 번호의 유효성 검사
        - 총 16자리
        - 마지막 숫자를 룬 알고리듬으로 만듦
      - 체크섬 알고리듬은 매우 간단
        - 보통 간단한 산술 연산
        - 계산이 빠르고 추가 메모리가 거의 불필요
          - 네트워크 프로토콜에서 사용
          - 하드웨어로도 구현하기 쉬움
        - 단, 모든 오류를 찾지는 못함
      - 체크섬은 데이터가 바뀐지만 확인
        - 보통 복구는 신경 쓰지 않음
        - 따라서 체크섬이 일치하지 않으면, 데이트 전송의 경우는 재전송 요청
        - 저장 중인 데이터라면..날아감
        - 데이터 복구를 지원하는 것도 있음
    - 패리티 비트(parity bit)
      - 비암호학적 해시
      - 체크섬중 하나
      - 이진수로 저장된 데이터에 추가하는 1비트짜리 체크섬
      - 보통 1바이트 단위로 많이 사용(7비트 데이터 + 1비트 패리티)
      - 짝수 패리티와 홀수 패리티로 나뉨
        - 패리티까지 포함한 모든 비트를 더하면 그 결과가 짝수 또는 홀수가 되어야 함
      - ex) 데이터 : 000 0000 / 1비트 갯수 : 0 / 홀수패리티 : 1000 0000 / 짝수패리티 : 0000 0000
      - ex) 데이터 : 010 1100 / 1비트 갯수 : 3 / 홀수패리티 : 0010 1100 / 짝수패리티 : 1010 1100
      - ex) 데이터 : 111 1111 / 1비트 갯수 : 7 / 홀수패리티 : 0111 1111 / 짝수패리티 : 1111 1111
    - 순환중복 검사(cyclic redundancy check)
      - 비암호학적 해시
      - 체크섬중 하나
      - 다항식의 나머지 연산을 이용하여 검사값을 만듦
        - 검사값은 보통 고정된 길이
        - 따라서 CRC함수를 해시 함수로 사용하기도 함
      - 역시 이진수 하드웨어에서 구현하기 쉬움
        - 심지어 최신 CPU는 CRC-32C명령어를 탑재
      - 다항식의 최고차항에 따라 CRC에 사용하는 비트 수가 달라짐
        - 각 항의 계수는 1 아니면 0
        - 최고차항의 계수는 언제나 1
        - 예) x³ + x + 1 -> 1011(총4비트)
        - 최고차항은 언제나 1이기 때문에 -> 011 이렇게 표현할 수 있음
      - CRC알고리듬들
        - CRC-8
        - CRC-16
        - CRC-32
        - CRC-64

<br/>

  - 암호학적 해시 알고리듬
    - 해시값에서 원본 값을 찾는게 사실상 실행 불가능한 알고리듬
      - 일방향 함수
      - 수학적인 지식이 많이 요구되는 부분
      - 따라서 이미 있는 해시 함수를 주로 사용
    - 원본 값을 찾으려면 모든 조합을 모두 시도해봐야 함(무차별 대입 공격)
    - 보안 분야에서 다양한 용도로 사용
    - 예시
      - 메시지나 파일의 무결성 검사
      - 디지털 서명 생성 및 검증
      - 비밀번호 검증
      - 작업 증명
        - 블록체인 등에서 서비스 거부 공격을 어렵게 만들기 위해
      - 일반 해시 알고리듬 대신으로 사용 가능
    - 암호학적 해시 알고리듬의 예
      - MD5
      - SHA-1
      - SHA-256
      - SHA-512

<br/>

  - 암호학적 해시 알고리듬의 추가 속성
    - 역상 저항성(pre-image resistance)
      - 해시값으로부터 원본 데이터를 찾기가 어려워야 함
        - 원본 데이터를 같이 저장하지 않는 용도에 적합
      - 비보안학적 해시 함수에서 본 비트 패킹은 역상 저항성이 거의 없음
        - 낮은 역상 저항성을 이용하는 게 역상 공격
        - 무차별 대입 공격을 통해서만 해시값을 찾을 수 있는 것이 이상적
      - 즉, 해시 값으로 부터 패턴을 보기 어려워야 함
        - 해시값의 길이가 길수록 좋음
    - 제2 역상 저항성
      - 똑같은 해시값이 나오는 다른 입력값을 찾기 어려워야함
        - (입력값, 해시값) 쌍을 이미 가지고 있을 때
        - 이 저항성이 낮으면 제 2 역상 공격에 취약함
      - 역상 저항성 보다 한 가지 정보가 더 있는 경우
        - 역상 저항성은 해시값만 있음
        - 제 2역상 저항성은 입력값도 알고 있음
    - 충돌 저항성
      - 해시값이 똑같은 두 입력값을 찾기가 어려워야 함
        - 해시값도 입력값도 주어지지 않은 경우
        - 이 저항성이 낮으면 충돌 공격에 취약
      - 충돌 공격은 역상 공격들 보다 쉬움
        - 이미 MD5와 SHA-1에 대해 실행 가능한 충돌 공격이 발견됨
        - MD5는 일반 컴퓨터로 몇 초면 충분할 정도
        - 모든 암호학적 해시 함수는 생일 공격이 가능하기 때문
        - 생일 공격은 무차별 대입 공격보다 빠름
        - 생일문제
          - 회사직원 수는 20명, 이 중에 생일이 9월1일인 직원이 있을 확률은? : 5.3%(역상 공격과 비슷)
          - 회사직원 수는 20명, 그냥 생일이 겹치는 사람이 있을 확률은? : 41.1%(충돌 공격과 비슷)
        - 생일문제는 출력값의 길이가 정해져 있기에 생기는 문제임
          - 모든 암호학적 해시 함수가 생일 공격에 노출되어 있는 이유
        - 출력값의 길이를 늘리면 그 확률을 줄일 수 있음
          - 해시값의 크기가 클수록 좋은 이유

<br/>

  - 비밀번호를 해시로 저장해야 하는 이유
    - 웹사이트에서 모든 조합의 비밀번호를 시도하는 건 보호하지 않음
      - 해시값을 몰라도 DB와 비교해서 로그인 해주기 때문
      - 무차별 대입 공격은 여러 제약이 있음
        - 웹페이지 갱신 속도
        - 5번 실패 후, 계정 잠금 등
    - 데이터 베이스가 털렸을 때 비밀번호가 노출되는 걸 막음
      - 사람들은 같은 비밀번호를 여러 사이트에 사용
      - 각 사이트마다 다른 비밀번호를 사용해야 하는 이유
  - 해시에서 비밀번호를 찾는 법
    - 1. 해커의 컴퓨터에서 모든 조합의 비밀번호를 시도(무차별 대입 공격)
      - 웹에서 시도할 때의 제약을 받지 않음
      - 하드웨어 가속도 가능
        - 싸구려 그래픽 카드 하나로 초당 100억 개 이상의 MD-5를 계산할 수 있음
        - 영어 대소문자 8자리로 만들 수 있는 비밀번호는 약 534597억 개
        - 전부 시도하는데 걸리는 시간 1.5시간 미만
      - 하드웨어서만 효율성이 떨어지는 알고리듬을 선호
      - 비밀번호는 길수록 좋음
    - 2. 해커의 컴퓨터에서 사전에 있는 단어들로 시도(사전 공격)
      - 무차별 대입 공격과 기본은 같음
      - 하지만 사전에 있는 단어들을 조합해가며 시도
        - 사람들은 보통 기억하기 쉬운 단어를 비밀번호로 사용
        - 무차별 대입 공격보다 빠름
      - 비밀번호 생성기에서 생성한 뷁스러운 비밀번호가 더 나은 이유
    - 3. 해커가 가지고 있는 레인보우 테이블과 비교
      - 레인보우 테이블 : 미리 계산해 놓은 해시값의 목록
        - 흔히 사용하는 비밀번호들을 모두 계산한 결과를 저장
        - 흔히 사용하는 모든 해시 함수에 대해
      - 레인보우 테이블과 일치하는 해시값이 저장되어 있다면 찾는 시간은
        - 해시 테이블과 같음
        - O(1)
    - 1,2,3번 모두 시중에 알려져 있는 해시 함수를 사용해서 생기는 문제이다!
    - 하지만 독자적인 해시 함수를 사용하는것 또한 좋지 않다
  - 독자적인 해시 함수 사용이 안 좋은 이유
    - 보안업계에서 독자적인 암호학적 해시 함수 사용을 비추
      - 어떤 취약점이 있는지 알 수 없음
      - 보안감사를 제대로 하지 않음
      - 따라서 전문가들은 자체 암호화 기법을 사용하는 서비스를 피함
    - 공개적으로 검증된 해시 함수를 주로 사용
      - 초천재 수학자들과 보안전문가들이 개발 및 감사를 한 것들
      - 막강한 정부의 자금과 인력도 투입
      - 취약점이 발견되면 다 같이 털린다는 문제가 있음
      - 정부에 대한 음모론도 존재…
  - 비밀번호 덜 털리는 법
    - 1. 이미 털렸다고 알려진 비밀번호를 설정 못하게 한다
      - 대규모로 털린 비밀번호 목록을 웹에서 찾을 수 있음(API도 존재)
      - 그 비밀번호를 입력하면 다른 비밀번호를 만들라고 강제
    - 2. 긴 비밀번호를 사용하게 강제한다
      - 비밀번호의 자릿수가 늘어나면 시도해야 할 조합이 기하급수적으로 증가
    - 3. 아예 비밀번호를 저장하지 않는다
      - 이메일로 보낸 링크를 클릭하면 로그인이 되는 방법
      - 소셜 로그인만 받는 방법
    - 4. 비밀번호를 처음 저장할 때 랜덤 문자열도 같이 저장
      - 더 이상 레인보우 테이블에서 찾을 수 없음
      - 각 비밀번호마다 무차별 대입 공격 및 사전 공격을 해야 함
    - 5. 모든 비밀번호에 붙이는 공통된 문자열을 붙인다
      - 데이터 베이스에 저장하지 않고 웹 서비스에서만 알고 있는 값
        - 해커가 가지고 있지 않기에 거의 모든 공격을 무력화
        - 단, 데이터베이스 털릴 때, 웹 서버 메모리까지 털리면 도루묵..
    - 6. 업계에서 최고의 해시 함수라고 말하는 것을 선택할것
    - 7. 보안 관련 뉴스를 구독할 것
      - 해시 함수는 언제든 깨질 수 있음
      - 그러면 재빨리 더 나은 함수로 바꿔야 함
      - 해시 함수가 바뀌니 비밀번호를 다 리셋해야함
    - 8. 비밀번호 찾기를 허용하는 웹사이트를 조심할 것
      - 리셋이 아닌 찾기를 허용한다면 내 비밀번호가 저장되어 있다는 말

###### [해시 알고리듬](#해시-알고리듬)
###### [Top](#top)

<br/>
<br/>

***

# 암호화
  - 암호화(encryption)
    - 평문을 암호문으로 변환하는 것
      - 평문 : 누구나 읽으면 곧바로 이해할 수 있는 정보
      - 암호문 : 읽는다고 모두가 이해할 수는 없는 정보
    - 암호문도 누군가 훔쳐볼 수 있음
    - 단, 특별한 정보를 아는 사람만 이해할 수 있음
  - 복호화(decryption)
    - 암호문을 다시 평문으로 변환하는 것
    - 암호화에 사용한 방법을 알아야 빨리 복호화 가능
  - 해시 알고리듬은 원문 복구를 막는 게 목표
  - 암호화 알고리듬은 원문 복구를 허용해야 함

<br/>

  - 정수론(number theory)
    - 정수의 성질에 대해 연구하는 학문
    - 과거에는 실용적으로 써먹을 곳이 없었음
    - 2진수로 표현된 데이터를 암호화하려다 보니 갑자기 주목 받음
      - 결국 2진수도 정수이기 때문
    - 특히 소수에 관련된 정수론적 알고리듬이 많은 주목을 받음
      - 암호문의 패턴을 들키지 않으려면 겹치지 않는 수가 필요
      - 소수는 자연에서 가장 안 겹치는 수
  - 암호학에서 사용하는 정수
    - 매우 큰 정수
      - 흔히 사용하는 32비트 등의 정수가 아님
      - 32비트 범위 안에 있는 소수는 오직 203,280,220개 뿐
    - 입력 크기 N
      - 보통 배열 속의 요소 수를 의미
      - 암호학에서 사용하는 정수에서는 비트 수를 의미
    - 곱셈, 나눗셈, 나머지 연산의 시간 복잡도
      - 보통 정수는 O(1)
      - 암호학에서 사용하는 정수는 비트 수에 비례

<br/>

  - 스트림 암호 vs 블록 암호
    - 스트림 암호( stream cipher)
      - 한 번에 1바이트씩 받아 암호화를 진행
      - 안전하려면 각 바이트에 적용하는 키가 달라야 함
        - 보통 시드 값을 정하고 난수로 생성
      - 블록 암호보다 설정이 복잡하나 속도가 빠름
    - 블록 암호(block cipher)
      - 정해진 블록 크기(64비트 이상)만큼의 바이트를 한 번에 암호화
      - 각 블록에 사용하는 키가 동일함
      - 스트림 암호보다 설정이 간단하나 속도가 느림

<br/>

  - 현대에 사용하는 암호화 알고리듬 두 종류
    - 1. 대칭 키 암호화(symmetric-key encryption)
      - 암호화/복호화에 동일한 키 를 사용
    - 2. 비대칭 키 암호화(asymmetric-key encryption)
      - 공개 키 암호화(public-key encryption)라고도 함
      - 암호화와 복호화에 사용하는 키가 다름
  - 대칭 키 암호화
    - 암호화/복호화에 동일한 키를 사용
    - 이 키는 메시지 송신자와 수신자가 공유하는 비밀
      - 수신자가 이미 그 키를 가지고 있어야 복호화 가능
    - 송신자가 수신자에게 비밀스럽게 키를 알려줄 방법이 필요
      - 다른 사람들은 몰라야 비밀 유지가 됨
      - 대칭 키 암호화의 가장 큰 단점
    - Wi-Fi비밀번호도 일종의 대칭 키
      - 공유기에 설정하는 비밀번호와 스마트폰에 입력하는 키가 같음
      - 스마트폰과 공유기 사이에 통신할 때 이 키로 암호화를 함
      - WPA2-Personal은 이런 식으로 작동
        - 스마트폰이 처음 공유기에 접속 시 교환하는 어떤 값과 비밀번호를 합쳐 키 생성
        - 그 키를 이용해서 메시지를 암호화
        - 따라서 모든 접속자마다 다른 키를 사용
        - 하지만 해커가 둘 사이의 모든 트래픽을 캡쳐한다면 읽기 가능
          - 결국 키를 왔다 갔다 하는 순간이 있기 때문
    - 대칭 키 알고리듬 목록
      - DES, IDEA, Blowfish, AES, RC4, RC5, RC6, 등
  - AES
    - NSA에서 일급비밀 용으로 승인한 유일한 공개 암호화 알고리듬
    - 현재 가장 널리 사용되는 대칭 키 알고리듬
      - WPA2프로토콜의 일부로 사용되기도 함
    - 블록 크기 : 128비트
    - 키 길이 : 128, 192 또는 256비트
    - 키 길이에 따라 평문을 암호문으로 변환하는 라운드 수가 다름
      - 128비트 : 10라운드
      - 192비트 : 12라운드
      - 256비트 : 14라운드
    - AES는 한 번에 16바이트씩 읽어서 암호화
    - 평문의 원문을 16바이트  4 x 4행렬로 배치
    - 그 뒤 여러 처리 과정을 통해 암호화를 진행
    - AES 알고리듬의 구성
      - 1. 키 확장(key expansion)
        - 대칭 키로부터 각 라운드에 사용할 여러 키를 생성
          - 이를 라운드 키라고 부름
          - 생성법이 궁금하면 AES key schedule을 검색하기
        - 총 라운드 수 + 1 개의 라운드 키를 만듦
          - 즉, 각 라운드마다 다른 키를 사용
        - 대칭 키의 길이는 128/192/256 비트 중 하나
        - 그로부터 생성한 라운드 키는 모두 128비트
      - 2. 0라운드
        - a) 라운드 키 더하기
          - 더한다는 의미는 배타함(xor)
          - 평문의 원문의 16바이트 4 x 4행렬에 0라운드 키를 xor함
      - 3. 9/11/13 라운드
        - a) 0라운드에서 나온 행렬의 각 바이트를 다른 바이트로 대체함
          - AES S-Box라는 룩업 테이블을 사용함
          - 선형적인 변환이 아니기 때문에 단순 사칙 또는 비트 연산으로 찾을 수 없다(혼돈 효과를 성취)
        - b) 행 이동
          - 4개의 행을 각각 다르게 왼쪽으로 이동
            - 1행 : 이동 없음
            - 2행 : 1만큼
            - 3행 : 2만큼
            - 4행 : 3만큼
          - 확산 효과를 성취
        - c) 열 섞기
          - 각 열에 있는 4바이트를 선형적으로 변환
        - d) 라운드 키 더하기
      - 4. 최종 라운드 (총 라운드 수가 10/12/14 가됨)
        - a) 바이트 대체
        - b) 행 이동
        - c) 라운드 키 더하기
      - AES 알고리듬 나중에 더 자세히 알아보자!!

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/4f3e15f2-64a9-443e-a7cb-63c1daf175af)

<br/>

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/90851ebc-43f6-4ce7-81f6-a21f79132ddc)

<br/>

  - 비대칭 키 암호화
    - 대칭 키 암호화는 훌륭한 기법이며 쓸 곳도 많음
      - 하드디스크에 파일을 암호화하여 저장
      - 데이터베이스에 고객 정보를 저장
      - 사내 서버 간 통신의 암호화
    - 하지만 암호화/복호화에 동일한 키를 사용해서 가끔 발목이 잡힘
      - 메시지 교환 용으로 사용할 때 안전하게 키를 배포하기가 힘듦
    - 보안 문제 없이 쉽게 키를 배포 할 수 있는 방법이 필요
    - 비대칭 키
      - 암호화와 복호화에 사용하는 키가 다름
      - 두 키 사이에는 특수한 수학적인 관계가 있음
        - 둘 중 한 키로 암호화한 메시지를 다른 키로 복호화할 수 있음
      - 따라서 키 하나는 완전히 공개해 놓아도 상관 없음
        - 이 키를 공개키(public key) 라고 부름
        - 비대칭 키 암호화를 공개 키 암호화라고도 부르는 이유도 이것 때문
      - 다른 키 하나는 한 개인이 비밀로 가지고 있음
        - 이 키를 비밀 키 또는 개인 키(private key) 라고 부름
  - 메시지 암호화
    - 송신자가 수신자의 공개 키로 원문 -> 암호문
      - 키가 공개돼 있으니 누구나 암호화 가능
      - 공개 키로는 암호문 -> 원문 변환 불가
    - 수신자는 자신의 비밀 키로 암호문 -> 원문 변환
      - 수신자만 알고 있는 키
      - 수산지만 원문을 볼 수 있음
  - 비대칭 키 암호화의 두 가지 주요 용도
    - 1. 전송하는 메시지의 암호화
      - 다른 사람이 원문을 못 보게 숨김
    - 2. 전자서명
      - 메시지는 누구든 볼 수 있음
      - 메시지 송신자가 올바름을 증명
      - 처음에 봤던 예
      - 암호화폐에서 돈을 옮길 때도 이 방법을 사용
      - 전자서명은 내가 가지고 있는 나의 비밀키로 암호화 해서 공개되어 있는 나의 은행창구에 보내고, 그곳에서 나의 공개키로 풀었을때 풀린다면 나라는 것은 인증하는 것이기 때문에 접근 가능하게 된다
  - 비대칭 키 암호화를 사용하는 곳
    - HTTPS
      - 비대칭 키 암호화와 더불어 대칭 키 암호화도 사용
    - 메신저 앱의 비밀 채팅 모드
      - 서버도 내 비밀 키를 모르는 모드
    - 비트코인 등의 암호화폐 프로토콜
    - Git 커밋의 전자서명
      - GitHub에서 지원하는 GPG키
  - 대표적인 비대칭 키 암호화 기법
    - 디피-헬만 키 교환
    - RSA
    - 디지털 서명 알고리듬
    - 타원곡선 DSA
  - 소수의 특징
    - 소수는 더 이상 인수분해가 안 되는 숫자
      - 1과 소수 그 자체로만 나눠짐
    - 서로 다른 두 소수  p, q를 곱하면 합성수 n이 나옴
    - n의 인수는 p와, q뿐
  - RSA
    - 현재 데이터 전송용으로 매우 널리 쓰이는 암호화 기법
    - 정수론에 기초해 놀라운 일들을 성취
    - 공개 키/비밀 키 쌍을 만드는 게 매우 쉬움
      - 매우 큰 두 소수를 이용
    - 이 두 키는 특수한 수학적 관계를 가짐
      - 공개 키를 알아도 그로부터 비밀 키를 찾기 매우 힘듦
      - 거듭제곱과 나머지 연산만으로 암호화 가능
      - 암호문을 다시 거듭제곱한 뒤, 나머지 연산을 하면 원문이 돌아옴
    - RSA가 이용하는 소수의 성질
      - 두 소수를 곱하는 것은 쉽게 할 수 있음
      - 두 소수를 곱한 합성수에서 그 소수들을 찾는 것은 훨씬 어려움
        - 이렇다 할 알고리듬이 없어 모든 조합을 곱해봐야 함
    - RSA 키 길이와 연산 속도
      - NIST에서 권하는 RSA의 키 길이
        - 2002년 : 1024비트
        - 2015년 : 2048비트
      - RSA-2048은 1024 비트 소수를 2개 사용
        - 즉, 308자리 숫자
      - 혹시라도 컴퓨터 속도가 더 빨라지면 비트 수를 늘리면 됨
    - RSA 공개 키/비밀 키의 기초
      - 비밀키 : 아주 큰 소수 p,q
        - p, q자체가 비밀키는 아니며, 비밀키의 일부이다
      - 공개키 : 합성수 n (n = p x q)
        - n 자체가 공개키는 아니며 공개키의 일부이다
      - p, q를 모르면 n으로부터 p, q를 찾기가 매우 힘듦
        - 즉, 공개 키로부터 비밀 키를 찾기가 매우 힘듦
        - 이것이 RSA공개 키/비밀 키 간의 첫 번째 특수한 관계
      - p, q와 특수한, 그리고 서로 간에도 특수한 관계인 e와 d를 찾음
        - e : 공개 키의 두 번째 요소가 됨
        - d : 비밀 키의 두 번째 요소가 됨
      - e와 d또한 특수한 관계를 만족해야 함
        - 나중에 검색해보기

<br/>

  - RSA키 생성
    - 1. 매우 큰 두 소수 p와 q를 찾는다
      - a. 매우 큰 랜덤 수를 뽑는다
      - b. 그 수가 소수인지 판별한다
      - c. 소수가 아니라고 판별되면 1번 단계로 돌아간다
      - d. 서로 다른 두 소수를 찾을 때까지 이 과정을 반복한다
      - ex) p = 57, q = 53
    - p와 q를 곱해 n을 만든다
      - n = 67 x 53 = 3551
    - p, q와 특수한 수학적 관계인 e를 찾는다
      - 1. n의 카마이클 수를 구한다 = 1716
      - 2, 이것에서 다른 찾는 방법을 통해서 e값을 찾아낸다(나중에 자세하게 공부해보자)
    - e와 특수한 수학적 관계인 d를 찾는다
      - 확장 유클리드 호제법을 사용하면 쉽게 찾을 수 있음
  - RSA를 이용한 암호화
    - 원문에 e승을 한후 n으로 나머지 연산을 한 나머지가 암호문이 된다
  - RSA를 이용한 복호화
    - 암호문에 d승을 한후 n으로 나머지 연산을 한 나머지가 원문이 된다
  - RSA를 증명하기..
    - 나중에 더 자세히 공부해보자..
  - 증명 과정에서 본 정리들
    - 정수의 성질을 공부하는 정수론에 속함
    - 실용성이 없다 여기던 학문을 암호학에 적용해 불가능한 일을 성취
    - 우리가 수학자들을 존경해야 하는 이유..

<br/>

  - 대칭 키 vs 비대칭 키 암호화의 속도
    - 비대칭 키 암호화가 보통 더 느림
      - 키의 길이가 훨씬 김(매우 큰 수로 하는 연산)
      - 알고리듬 자체가 더 복잡
      - 위 두 가지 이유는 결국 하나의 키를 공개하기 때문
    - 그래서 비대칭/대칭 키 암호화를 같이 사용하기도 함
      - 예) 세션동안 사용할 대칭 키를 비대칭 키 암호화를 이용해 전송

###### [암호화](#암호화)
###### [Top](#top)

<br/>
<br/>

***

# 트리
  - 트리
    - 매우 널리 사용하는 자료구조 중 하나
    - 나무(tree)의 계층적 구조를 표현
  - 트리 관련 용어
    - 노드(node) : 실제로 저장하는 데이터
    - 루트(root) 노드 : 최상위에 위치한 데이터
      - 시작 노드
      - 모든 노드와 직간접적으로 연결됨
    - 리프(leaf)노드 : 마지막에 위치한 데이터들
    - 부모-자식 : 연결된 노드들 간의 상대적 관계
      - 자식은 없을 수도, 많이 있을 수도
      - 부모는 언제나 1
      - 조부모/삼촌/형제자매도 있음
    - 깊이(depth) : 노드 -> 루트 경로의 길이
    - 높이(height) : 노드 -> 리프 경로의 최대 길이
    - 하위 트리(subtree) : 어떤 노드 아래의 모든 것을 포함하는 트리
      - 재귀적 : 하위 트리 그 자체가 트리!

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/79938397-798b-48d1-a80a-3f715fa65a16)

<br/>

  - 트리의 속성
    - 1. 부모와 자식 모두 노드
    - 2. 부모 : 자식 = 1 : 다수
    - 3. 자식은 언제나 부모로부터 가지를 침
    - 따라서 부모가 자식을 참조하는 방식이 가장 직관적
  - 범용적 트리의 저장법

~~~c#
public class Node
{
    public int data;
    public List<Node>? children;
}
~~~

<br/>

  - 자식이 최대 둘인 트리의 저장법(이진트리)
    - 위의 코드는 범용적이기 때문에 위의 것도 상관 없지만 List라는 것이 2개 이상 몇개라도 넣을 수 있기 때문에 제한을 가하는것이 사실은 좋은 코드가 된다

~~~c#
public class Node
{
    public int data;
    public Node? left;
    public Node? right;
}
~~~

<br/>

  - 자식이 최대 하나인 트리의 저장법
    - 연결리스트!, 따라서 연결리스트란 사실 트리에서 어떤 제약을 가한 자료구조라고 생각할 수 있다

~~~c#
public class Node
{
    public int data;
    public Node? child;
}
~~~

<br/>

  - 트리의 용도
    - 계층적 데이터를 표현
      - HTML이나 XML의 문서 개체 모델(DOM)을 표현
      - JSON이나 YAML 처리 시 계층 관계를 표현
      - 프로그래밍 언어를 표현하는 추상 구문 트리(abstract syntax tree)
      - 인간 언어를 표현하는 파싱 트리(parsing tree)
    - 검색 트리를 통해 효율적인 검색 알고리듬 구현 가능
    - 그 외 다수

###### [트리](#트리)
###### [Top](#top)

<br/>
<br/>

***

# 이진 탐색 트리
  - 이진 탐색 트리
    - 트리에는 다양한 트리가 있고, 그중에 자식이 최대 둘인 트리인 이진 트리가 있다. 그 이진 트리중 특수한 형태가 이진 탐색 트리가 된다.
    - 하지만 이진 탐색 트리는 정말 많이 사용하기 때문에 트리 = 이진탐색트리라고 사용할 정도이다
    - 이진 트리
      - 자식이 최대 둘
        - 왼쪽/오른쪽 자식
      - 무언가 계층적(재귀적)으로 이분해 나갈 때 적합
      - 그 무언가를 이분하는 기준을 만든다면?
        - 그 기준에 따라 특화된 이진 트리를 만들 수 있음
        - 그에 따라 보다 효율적인 알고리듬 고안 가능
        - 한 가지 예인 이진 탐색 트리(binary search tree, BST)가 있다
    - 이진 탐색 트리(BST)
      - 이진 트리에 이분하는 규칙을 추가
        - ‘왼쪽 자식은 언제나 부모보다 작다’
        - ‘오른쪽 자식은 언제나 부모 이상’
          - 꼭 오른쪽이 ‘이상’으로 가지 않아도 왼쪽이 ‘이하’로 갈 수도 있으니 상관은 없다
      - 정렬된 트리(=정렬된 자료구조)
        - 정렬된 트리에서는 효율적인 알고리듬을 사용할 수 있다
          - 예 : 이진탐색
    - 정렬된 배열 vs 이진 탐색 트리
      - 정렬된 배열
        - 보통 이진 탐색 전에 정렬을 함
          - 삽입/삭제 할 때마다 정렬할 수도 있음
        - 새로 추가된 데이터는 비정렬 상태
        - (일단 정렬 후) 탐색 시간 : O(logn)
        - 삽입 및 삭제 : O(n)
        - 매우 간단한 데이터 구조
        - 메모리 한 덩어리
      - 이진 탐색 트리
        - 탐색 전에 따로 정렬 불필요
        - 데이터 추가 시 정렬된 위치에 추가
        - 탐색 시간 : O(logn)
        - 평균 삽입/삭제 시간 : O(logn)
        - 연결 리스트 이상 복잡한 데이터 구조
        - 보통 여러 메모리 덩어리

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/2753bd4b-50f1-4a43-bf68-9c63fa6ac724)

<br/>

  - 이진 탐색 트리 (BST, Binary Search Tree) 탐색
    - 기본적으로 이진 탐색과 동일
      - 분할 정복(재귀적)
    - 차이점
      - 각 노드마다 두 하위 트리로 이분됨
    - 하위 트리로 내려갈 때마다
      - 검색 공간이 절반씩 줄어듦 : O(logn)
      - 이진 트리가 최악인 상황은, 모든 트리의 자식이 한개 씩만 있어서 줄줄이로 되었을경우 : O(n)

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/fa0c8520-61bb-4d3d-bb3b-8aaa54b25a87)

<br/>

  - 이진 탐색 트리 (BST, Binary Search Tree) 삽입
    - 1. 새로운 노드를 받아줄 수 있는 부모 노드를 찾음
      - 트리를 내려가는 방법은 탐색과 같음
      - 새로운 노드를 받아줄 수 있는 부모란?
        - 오른쪽 하위 트리로 내려가야 하는데 오른쪽 자식이 없는 부모
        - 왼쪽 하위 트리로 내려가야 하는데 왼쪽 자식이 없는 부모
    - 2. 그후, 거기에 자식으로 추가
    - BST삽입은 기존 노드 위치를 하나도 바꾸지 않음, 새로 추가되는 값은 언제나 리프 노드!
  - 이진 탐색 트리 (BST, Binary Search Tree) 삭제
    - BST는 정렬된 배열과 개념상 같음
      - 중위 순회를 하면 정렬된 배열이 나옴
    - 따라서 노드를 삭제한 뒤에도 올바른 BST를 유지하려면
      - 정렬된 배열에서 값을 하나 삭제하듯이 처리
    - BST 노드 삭제 전략
      - 1. 지울 값을 가지고 있는 노드를 찾음
      - 2. 그 바로 전 값을 가진 노드를 찾음
        - 왼쪽 하위 트리의 제일 오른쪽 리프
      - 3. 두 값을 교환
      - 4. 리프 노드를 삭제
    - in-order successor
      - 오른쪽 하위 트리에서 최솟값(제일 왼쪽 리프)
    - in-order predecessor
      - 왼쪽 하위 트리에서 최댓값(제일 오른쪽 리프)
    - 이진 탐색 트리에서 삭제의 3가지
      - 단말 노드 삭제: 삭제하려는 노드가 자식이 없는 경우, 그냥 노드를 삭제
      - 한 쪽 자식만 있는 노드 삭제: 삭제하려는 노드가 하나의 자식만 가지고 있는 경우, 삭제하는 노드의 부모 노드를 삭제 노드의 자식 노드에 연결
      - 두 개의 자식을 가진 노드 삭제: 가장 복잡한 경우입니다. 삭제하려는 노드가 두 개의 자식을 가지고 있을 때, 삭제 노드의 오른쪽 서브트리에서 가장 작은 값을 가진 노드를 찾아 삭제 노드의 위치에 넣는다. 이를 위해 오른쪽 서브 트리에서 최소 값을 가진 노드를 찾아서 삭제 노드의 값으로 대체한 다음, 그 최소 값을 가진 노드를 실제로 삭제한다(왼쪽 서브트리에서 가장 큰 값을 이용해도 상관 없다)

<br/>

~~~c#
public class TreeNode
{
    public int Value { get; set; }
    public TreeNode Left { get; set; }
    public TreeNode Right { get; set; }

    public TreeNode(int value)
    {
        this.Value = value;
        this.Left = null;
        this.Right = null;
    }
}

public class BinarySearchTree
{
    public TreeNode Root { get; private set; }

    // 탐색 메서드
    public TreeNode Search(int value)
    {
        return Search(this.Root, value);
    }

    private TreeNode Search(TreeNode node, int value)
    {
        if (node == null || node.Value == value)
        {
            return node;
        }

        if (value < node.Value)
        {
            return Search(node.Left, value);
        }
        else
        {
            return Search(node.Right, value);
        }
    }

    // 삽입 메서드
    public void Insert(int value)
    {
        this.Root = Insert(this.Root, value);
    }

    private TreeNode Insert(TreeNode node, int value)
    {
        if (node == null)
        {
            return new TreeNode(value);
        }

        if (value < node.Value)
        {
            node.Left = Insert(node.Left, value);
        }
        else if (value > node.Value)
        {
            node.Right = Insert(node.Right, value);
        }

        return node;
    }

    // 삭제 메서드
    public void Delete(int value)
    {
        this.Root = Delete(this.Root, value);
    }

    private TreeNode Delete(TreeNode node, int value)
    {
        if (node == null) return node;

        if (value < node.Value)
        {
            node.Left = Delete(node.Left, value);
        }
        else if (value > node.Value)
        {
            node.Right = Delete(node.Right, value);
        }
        else
        {
            if (node.Left == null)
            {
                // 왼쪽 자식이 없으면, 오른쪽 자식(또는 null)을 부모 노드에 연결합니다.
                return node.Right;
            }
            else if (node.Right == null)
            {
                // 오른쪽 자식이 없으면, 왼쪽 자식을 부모 노드에 연결합니다.
                return node.Left;
            }

            // 오른쪽 서브트리에서 가장 작은 값을 찾아서, 현재 노드에의 값으로 대체합니다.
            node.Value = MinValue(node.Right);

            // 오른쪽 서브트리에서 이 최소 값을 가진 노드를 삭제합니다
            node.Right = Delete(node.Right, node.Value);
        }

        return node;
    }

    private int MinValue(TreeNode node)
    {
        int minValue = node.Value;
        while (node.Left != null)
        {
            minValue = node.Left.Value;
            node = node.Left;
        }
        return minValue;
    }
}
~~~

<br/>

  - 정리
    - 이진 탐색 트리 (BST, Binary Search Tree)는 일반 이진 트리에 하나를 더한것이고 그것은 하나의 규칙을 추가한것 뿐
      - ‘왼쪽 자식은 언제나 부모보다 작다’
      - ‘오른쪽 자식은 언제나 부모 이상’

###### [이진 탐색 트리](#이진-탐색-트리)
###### [Top](#top)

<br/>
<br/>

***

# 트리 순회(tree traversal)
  - 대표적인 3가지 트리 순회법
    - 전위(pre-order) 순회
    - 중위(in-order) 순회
    - 후위(post-order) 순회
  - 하위 트리와 비교했을 때 현재 노드의 방문 순서
    - 중위 : 왼쪽 하위 트리 -> 현재 노드 -> 오른쪽 하위 트리
    - 전위 : 현재노드 -> 왼쪽 하위 트리 -> 오른쪽 하위 트리
      - 용도1 : 트리 복사
        - 부모가 있어야 자식도  추가할 수 있음
        - 따라서 전위 순회가 적합
          - 부모를 먼저 나열
          - 다른 순회는 부모가 중간 혹은 마지막
      - 용도2 : 수식의 전위 표기법
        - 수식은 보통 중위 표기법을 사용
          - 괄호로 우선 순위를 정해줄 수 있음
    - 후위 : 왼쪽 하위 트리 -> 오른쪽 하위 트리 -> 현재 노드


###### [트리 순회(tree traversal)](#트리-순회tree-traversal)
###### [Top](#top)

<br/>
<br/>

***

# 레드-블랙 트리(red-black tree)
  - 각 노드가 레드 혹은 블랙
    - 노드에 저장하는 데이터가 아님
    - 그냥 1비트짜리 추가 정보(굳이 빨강/검정이 아니어도 됨)
  - 스스로 균형을 잡는(self-balancing) 트리
    - 그걸 통해 트리 높이를 최소로 보장
    - 균형을 잡는 시점은 삽입과 삭제 시
    - 그 외 연산은 BST와 동일(단, 탐색 속도가 BST보다 빠를 것임)
  - 레드-블랙 트리의 특성(properties)
    - 1. 노드는 레드 또는 블랙이다
    - 2. 루트 노드는 블랙이다
    - 3. 모든 리프 노드(NIL)는 블랙이다
      - 레드-블랙에서는 NULL포인터가 언제나 리프 노드가 된다
    - 4. 레드 노드의 자식은 모두 블랙이다
    - 5. 어떤 노드와 리프 사이에 있는 블랙 노드 수는 동일하다
      - 블랙 노드에만 있는 제약
      - 이를 통해 블랙과 레드 노드 수의 균형을 맞춤
      - 이걸 위해 삽입/삭제 시 트리를 재배치하거나 노드의 색을 바꾸기도 함
    - 이런 특성의 영향들
      - 리프 노드는 데이터를 담지 않음(NIL)
      - 다음과 같은 용어가 탄생
        - 블랙 깊이(black depth) : 루트와 어떤 노드 사이에 있는 블랙 노드 수
        - 블랙 깊이(black height) : 어떤 노드와 리프 사이에 있는 블랙 수
      - 가장 큰 리프 깊이가 가장 작은 것의 2배를 넘지 않음
        - 레드-블랙 트리가 보장하는 핵심 특성
        - 이진 트리 연산 시간이 O(N)이 되는 최악의 경우를 방지 즉, O(logn)을 보장
        - C++의 std::map의 구현으로 일반적으로 사용되는 자료구조!

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/7e55d012-765e-4e4f-a069-2cc3407b8603)

<br/>

  - 레드-블랙 트리가 보장하는 핵심 특성의 “증명”
    - 블랙 높이가 x인 트리가 있다고 한다면, 루트 -> 리프의 길이가 최소인 경우는?
      - 블랙 : x개 즉, 모든게 블랙일 경우
      - 레드 : 0개
    - 이제 레드 노드를 최대한 집어 넣으려 시도 하게 되면, 블랙 노드 사이에 하나씩만 넣을 수 있게 된다
    - 따라서 루트 -> 리프의 최대 길이는 2x개의 노드로 구성
      - 참고 : NIL 리프 노드는 세지 않았음
  - 레드-블랙 트리의 연산
    - 탐색 : 이진 탐색 트리와 같음
      - 단, O(logn)을 보장
    - 삽입과 삭제
      - 일단 무작정 삽입 혹은 삭제(특성이 망가질 수 있음)
      - 그 후, 망가진 특성을 고치려 트리의 구조를 재배치(회전) 혹은 노드 색을 바꿈
      - 완벽하진 않지만 탐색 시간 O(logn)을 보장할 정도의 균형
      - 이 모두 O(logn)
        - 삽입 또는 삭제 O(logn) : 트리 깊이가 보장되기 때문
        - 트리 회전 : O(1)
        - 색 바꾸기 : O(1)

<br/>

  - 일반적인 레드-블랙 트리 삽입/삭제 원리
    - 삽입/삭제 원리를 스스로 알아내는 건 아마 천재의 영역
      - 사실 완전히 이해하는 것 조차 쉽지 않음
    - 하지만 실무자라면 최소한 감은 잡아야 함
    - 그 감에 의존해서 이런 일이 가능
      - 데이터를 보고 레드-블랙 트리를 적용해야 하는 상황을 인지
      - 실제 코드를 구현하고 적절한 데이터로 테스트
  - 레드-블랙 트리의 삽입 방법
    - 1. BST와 똑같이 삽입
      - 단, 새로 삽입하는 노드는 언제나 레드
      - 언제나 리프에 추가되니 아래 연산이 간단해짐
    - 2. 레드-블랙 트리의 조건을 만족하도록 재귀적으로 고침
      - 재귀 방향 : 리프로부터 위로 올라가면서
      - 고칠 때 사용하는 기법은 다음 두 가지
        - 트리 회전
        - 색깔 바꾸기
      - 총 4가지 상황에 따라 트리 회전, 색깔 바꾸기 기법을 다르게 적용
  - 레드-블랙 트리 삽입의 시간 복잡도
    - 노드를 리프에 삽입 : O(logn)
    - 새 노드 색을 레드로 칠함 : O(1)
    - 망가진 레드-블랙 트리의 특성을 고침 : O(logn)
      - 색상 바꾸기 : O(1)
      - 트리 회전 : O(1)
    - 즉, O(logn) 이 된다!!

<br/>

  - 일반적인 레드-블랙 트리 삭제 강의
    - 웬만한 강의에서 설명도 없이 은근슬쩍 넘어가는 내용
    - 하더라도 전략의 암기를 돕기 위해 이상한 비유를 듦
      - 레드는 화난 상태, 블랙은 차분한 상태
    - 케이스만 6개
      - 케이스 적용 전에 미리 전처리를 해야 함
  - 레드-블랙 트리의 삭제 방법
    - 1. BST에서 삭제하듯이 우선 삭제한다
      - 지우려는 값을 가진 노드를 찾음
      - 교환할 NIL 아닌 노드 M을 찾음
      - 값을 복사해옴(색은 복사 안함)
      - M을 지움
    - 2. 레드-블랙 트리의 특성이 망가진 걸 고치려 열심히 노력한다
  - 레드-블랙 트리 삭제의 시간 복잡도
    - BST 방식으로 노드를 제거 : O(logn)
    - 망가진 레드-블랙 트리의 특성을 고침 : O(logn)
      - 색상 바꾸기 : O(1)
      - 트리 회전 : O(1)
    - 즉, O(logn) 이 된다!!

###### [레드-블랙 트리(red-black tree)](#레드블랙-트리redblack-tree)
###### [Top](#top)

<br/>
<br/>

***

# 트라이(Trie), 공간분할 트리
  - 이진트리
    - 각 노드의 연결이 키에 따라 결정
    - 노드가 그 키를 저장
  - 트라이
    - 탐색 트리 중 하나
    - 다른 이름
      - digital tree
      - prefix tree
    - 노드가 키 전체를 저장하지 않음
      - 그 노드 위치 자체가 키를 결정
    - 어떤 집합 안에서 특정한 키를 찾을 때 사용
    - 키는 문자열인 경우가 보통
    - 노드 사이의 연결이 한 글자로 결정됨
      - 키 전부가 아님
  - 트라이의 용도
    - 사전 데이터의 저장
      - 용량을 더 차지할 수는 있지만, 탐색 속도가 향상 된다
    - 해시 테이블 대신 사용 가능
      - 충돌이 없음
      - 해시 테이블보다 최악의 경우에 더 빠름 -> O(k)
      - 허나 평균 O(1)이 아님
      - 표현하기 어려운 데이터 형도 있음 -> float
    - 트라이를 이용해서 자동완성 기능 같은것을 구현하기 쉽다

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/c7c489f3-075d-49ed-a9c0-a9da78db635f)

<br/>

  - 공간 분할 트리
    - 물체 그리기 요청 방법1 : 모두 요청
      - 모든 물체를 그려달라 함
      - 그래픽 카드가 모든 물체를 화면에 투영
        - 화면 밖에 있는 물체는 안 그려짐
        - 안/밖 판단을 하려면 여전히 투영 필요
      - 그래픽 프로그래밍에서 종종 병목점
    - 물체 그리기 요청 방법2 : 적당히 추려서 요청
      - 화면에 확실히 안 나올 물체들을 추려버림
        - 경계상자, 경계 구 등을 이용
      - 안 추려진 물체들만 그래픽 카드에 요청
        - 이것만 그래픽 카드가 화면에 투영
      - 여전히 모든 물체에 대해 투영 연산
        - 하지만 CPU에서 연산
        - 간단한 모양을 사용
    - 어떻게 하면 효율적일까? 아이디어!
      - 모든 물체를 계산해야 했던 이유
        - 2D배열을 훑는 것과 마찬가지
        - 이것을 트리로 표현하면됨 -> 쿼드 트리
    - 쿼드 트리(quadtree)
      - 사분 트리라고도 함
      - 재귀적으로 2D공간을 분할
      - 각 노드가 4개의 자식을 가짐
        - 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래
        - 현재 노드를 4개의 하위 사각 영역으로 나눔
      - 공간분할 트리!

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/fed60718-cbdd-4e14-aaba-fdda43e83836)

<br/>

  - 옥 트리(octree)
    - 재귀적으로 3D공간을 분할
    - 각 노드가 8개의 자식을 가짐
      - 쿼드 트리의 4자식 x 앞/뒤
      - 현재 노드를 8개의 하위 상자로 나눔
    - 3D프로그램에 종종 사용
      - 마인크래프트 같은 게임
      - 글로벌 일루미네이션효과
      - 등
  - 기타 공간분할 트리
    - BSP(이진 공간 분할 트리)
    - R 트리
    - k-d 트리
    - 등

###### [트라이(Trie), 공간분할 트리](#트라이trie-공간분할-트리)
###### [Top](#top)

<br/>
<br/>

***

# 깊이 우선 탐색, 너비 우선 탐색, 미니맥스
  - 깊이 우선 탐색
    - 한 우물부터 깊이 판다
    - 깊이 우선 탐색이라고 한다(DFS, Depth-First Search)
    - 왼쪽부터 가도 되고, 오른쪽 부터 가도 됨
    - 중위 순회와 매우 비슷
      - 하지만 중위 순회는 왼쪽 끝부터 가지면 DFS는 루트부터 가니까 조금 다르긴 함
      - 재귀 함수로 쉽게 작성할 수 있음
      - 비 재귀적으로도 가능(스택 자료 구조)
      - 중위 순회도 깊이 우선 탐색 기법 중 하나
    - 간단한 ‘미로 탈출하기’ 전략

~~~c#
// 깊이 우선 탐색
namespace ConsoleApp1
{
    public class Program
    {
        public static void DFS(TreeNode node)
        {
            if (node == null)
                return;

            // 현재 노드 처리 (예: 출력)
            Console.WriteLine(node.Value);

            // 모든 자식에 대해 DFS 재귀 호출
            foreach (var child in node.Children)
            {
                DFS(child);
            }
        }

        static void Main(string[] args)
        {
            // 트리 구성 예제
            var root = new TreeNode(1);
            var child1 = new TreeNode(2);
            var child2 = new TreeNode(3);
            root.AddChild(child1);
            root.AddChild(child2);
            var child1_1 = new TreeNode(4);
            var child1_2 = new TreeNode(5);
            child1.AddChild(child1_1);
            child1.AddChild(child1_2);

            // DFS 실행
            DFS(root);
        }
    }

    public class TreeNode
    {
        public int Value { get; set; }
        public List<TreeNode> Children { get; set; }

        public TreeNode(int value)
        {
            this.Value = value;
            this.Children = new List<TreeNode>();
        }

        // 자식 노드 추가 메소드
        public void AddChild(TreeNode child)
        {
            Children.Add(child);
        }
    }
}
~~~

<br/>

  - 너비 우선 탐색
    - 여러 우물을 동시에 같은 깊이로
    - 현재 깊이의 이웃 노드들을 우선 방문
      - 어느 한 가지부터 깊게 보지 않음
      - 현재 노드보다 얕은 노드는 모두 방문했음
    - 최단 경로 찾기에 적합

~~~c#
// 너비 우선 탐색
using System;
using System.Collections.Generic;

public class Program
{
    public static void BFS(TreeNode root)
    {
        if (root == null)
            return;

        Queue<TreeNode> queue = new Queue<TreeNode>();
        queue.Enqueue(root);

        while (queue.Count > 0)
        {
            TreeNode current = queue.Dequeue();
            Console.WriteLine(current.Value);

            foreach (var child in current.Children)
            {
                queue.Enqueue(child);
            }
        }
    }

    static void Main(string[] args)
    {
        // 트리 구성 예제
        var root = new TreeNode(1);
        var child1 = new TreeNode(2);
        var child2 = new TreeNode(3);
        root.AddChild(child1);
        root.AddChild(child2);
        var child1_1 = new TreeNode(4);
        var child1_2 = new TreeNode(5);
        child1.AddChild(child1_1);
        child1.AddChild(child1_2);

        // BFS 실행
        BFS(root);
    }
}
~~~

<br/>

  - 깊이 우선 vs 너비 우선
    - 깊이 우선 탐색(DFS)
      - 자식부터 검색
      - 관련 자료구조 : 스택
      - 장점
        - 재귀 함수 호출로 간단히 구현 가능
        - 보통 BFS보다 메모리 사용량이 적음
        - 캐시 메모리에 좀 더 친화적
        - 병렬처리에 더 적합
    - 너비 우선 탐색(BFS)
      - 이웃부터 탐색
      - 관련 자료구조 : 큐
      - 장점
        - 언제나 최소 깊이의 결과를 찾음
        - 깊이가 무한인 트리에도 사용 가능

<br/>

  - 미니맥스(minimax)
    - 최악의 경우 발생할 수 있는 손실을 최소화하려는 규칙
    - 게임이론, 결정이론, 통계학, 철학 등에서 널리 사용
    - 최초의 AI체스 월드 챔피언 Deep Blue가 사용한 알고리듬
      - 현재 챔피언은 기계학습 알고리듬
      - 여전히 미니맥스에 기초한 체스 AI도 상위권
    - 제로섬(zero-sum) 게임의 결정 알고리듬으로 적합
      - n명이 참가하는 제로섬 게임이론에서 시작한 알고리듬
      - 여전히 어떤 제로섬 게임에도 적용하기 적합
  - 미니맥스 알고리듬의 가정
    - 1. 상대방도 최적의 결정을 내림
      - 상대방도 이기는 게 목표
      - 랜덤하게 플레이하지 않음
    - 2. 게임이 순수히 전략적이여야 함
      - 운 같은 요소가 없어야 함
      - 따라서 포커나 브루마블 같은 게임에는 비적합
      - 그러나 운 까지도 고려하는 변형 알고리듬도 있음
  - 게임 트리를 전부 훑을 수 없는 경우
    - 특정 깊이 까지만 게임 트리를 만듦
      - 예 : 현재부터 깊이 3까지만
      - 3개의 수를 내다보는 것과 마찬가지 이야기
    - 마지막 깊이에서 점수를 계산해야 함
      - 확실히 승/패가 결정 안 난 상황
      - 근사치를 구함
      - 현재 보드 상태가 나에게 얼마나 유리한가
  - 나중에 추가로 더 공부해보기

###### [깊이 우선 탐색, 너비 우선 탐색, 미니맥스](#깊이-우선-탐색-너비-우선-탐색-미니맥스)
###### [Top](#top)

<br/>
<br/>

***

# 동적 계획법
  - 동적 계획법(dynamic programming, DP)
    - 특별한 속성을 가진 복잡한 문제를 푸는 방법
    - 복잡한 문제를 그보다 단순한 하위 문제로 나눠서 풂
      - 재귀적
      - 가장 단순한 문제 + 1은 그 다음으로 단순한 문제
      - 이걸 반복하면 원래의 복잡한 문제까지 해결
    - 당연히 모든 문제를 이렇게 풀 수는 없음
      - 특별한 속성이 필요
  - 복잡한 문제의 예 : 배낭 문제
    - 크기와 가격이 다른 여러 물품이 있음
    - 값어치가 최대가 되도록 물건 넣기
    - 당연히 배낭에는 크기 제한이 있음
    - 배낭 문제가 어려운 이유
      - 주먹구구식으로 풀 경우 모든 경우의 수를 따져봐야 함
      - 배낭에 들어가면서도 값어치가 최고인 조합이 답
      - 물품 하나가 추가될 때마다 경우의 수가 2배씩 뜀
        - 시간 복잡도 : O(2ⁿ) 
  - 메모이제이션(memoization)
    - 계산 결과를 캐시에 저장해 둔 뒤, 나중에 재사용하는 기법
      - 처음 계산할 때 그 결과를 캐시에 저장
      - 나중에 동일한 계산을 다시 하는 대신 저장해둔 값을 가져다 씀
      - 값비싼 계산(예 : 깊은 재귀 호출)에 적합
      - 최적화 기법 중 하나, 캐싱 기법 중 하나
    - 보통 함수가 매개변수에 따라 반환하는 값을 캐싱하는 것을 지칭
    - 컴퓨터 프로그래밍에서만 사용하는 용어
  - 동적 계획법과 메모이제이션
    - 전혀 다른 개념
      - 메모이제이션 : 실행된 결과를 기억해 뒀다가 재사용하는 최적화 기법
      - 동적 계획법 : 복잡한 문제를 하위 문제로 쪼개서 재귀적으로 푸는 방법
      - 하지만 동적 계획법 = 메모이제이션이라 흔히 오해함
        - 동적 계획법에서 툭하면 사용하는 기법이 메모이제이션이기 때문
        - 하지만 메모이제이션이 동적 계획법에 필수가 아님
        - 동적 계획법의 성능을 향상할 뿐, 다른 곳에서도 메모이제이션을 사용함

~~~c#
// 피보나치
using System;

class Program
{
    static int Fibonacci(int n)
    {
        if (n <= 1)
            return n;
        else
            return Fibonacci(n - 1) + Fibonacci(n - 2);
    }

    static void Main(string[] args)
    {
        Console.WriteLine(Fibonacci(10)); // 10번째 피보나치 수를 출력
    }
}
~~~

<br/>

~~~c#
// 메모이제이션을 활용한  피보나치
public class Program
{
    static int Fibonacci(int n, int[] cache)
    {
        if (n <= 1)
            return n;

        if (cache[n] != 0)
            return cache[n];


        int ret = Fibonacci(n - 1, cache) + Fibonacci(n - 2, cache);

        cache[n] = ret;
        return ret;
    }

    static void Main(string[] args)
    {
        int n = 10;
        int[] fib = new int[n + 2]; // 0번째와 1번째 값 포함
        Console.WriteLine(Fibonacci(n, fib)); // 10번째 피보나치 수를 출력
    }
}
~~~

<br/>

  - top-down 동적 계획법
    - 최종적으로 풀려고 하는 복잡한 문제(루트) 에서 시작
    - 필요에 따라 재귀적으로 하위 문제를 풂
      - 두 번 이상 평가하는 문제는 캐시 덕분에 계산 생략
      - 하위 문제를 평가하는 최적의 순서를 알 필요 없음
    - 기존의 재귀 함수를 크게 변경하지 않아도 됨
      - 그냥 캐시 로직을 추가할 뿐
      - 생각해내기도 구현하기도 편함

~~~c#
// 메모이제이션을 사용한, bottom-up 동적 계획법 피보나치
using System;

class Program
{
    static int Fibonacci(int n)
    {
        int[] fib = new int[n + 2]; // 0번째와 1번째 값 포함
        fib[0] = 0;
        fib[1] = 1;

        for (int i = 2; i <= n; i++)
        {
            fib[i] = fib[i - 1] + fib[i - 2];
        }

        return fib[n];
    }

    static void Main(string[] args)
    {
        Console.WriteLine(Fibonacci(10)); // 10번째 피보나치 수를 출력
    }
}
~~~

<br/>

  - bottom-up 동적 계획법
    - 가장 작은 문제(리프)부터 시작
    - 순서대로 그보다 하나 더 큰 문제를 풀어나감
      - 필요하지 않은 하위 문제도 평가할 수 있음
      - 문제를 잘 분석해서 최적의 순서를 찾아야 함
    - top-down 방식보다 보통 더 빠름
      - CPU 캐시에 좀 더 친화적
      - 재귀 함수 호출을 피할 수 있음
      - 모든 하위 문제를 평가할 필요가 없는 경우에는 예외
  - 속도 향상은 공짜가 아니다
    - 메모이제이션/타뷸레이션은 속도 향상을 위한 기법
    - 그걸 위해 메모리를 더 사용함
    - 시간 복잡도와 공간 복잡도가 반비례인 관계가 꽤 있음

<br/>

  - 동적 계획법으로 푸는 배낭 문제
    - 작은 배낭부터 최적의 해법을 찾아나감
      - 예 : 1칸 배남 -> 2칸 배낭 -> 3칸 배낭
    - 작은 배낭의 해법에 기초하여 원래 문제의 최적의 해법을 찾음
      - 예 : 1칸 배낭의 최적 해법 + 3칸 배낭의 최적 해법 = 4칸 배낭의 최적 해법
    - 우선 그리드를 만든다
      - 모든 동적 계획법 알고리듬은 그리드로 시작
      - 각 cell마다 간단한 결정(훔침 vs 안 훔침)을 내림
      - 각 cell의 값은 훔칠 수 있는 최댓값
    - cell[ i ][ j ]의 값은 다음 중 큰값
      - 현재 물품 추가 전의 최댓값(cell[ i - 1 ][ j ])
      - 현재 물품의 값 + 남은 공간에 넣을 수 있던 최댓값(cell[ i - 1 ][ j - item.space ])

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/64437c79-c2a2-4fa4-a5dd-ba02a0347592)

<br/>

  - 동적 계획법을 적용할 수 있는 문제의 특징
    - 1. 최적 부분 구조(optimal substructure)
      - 하위 문제의 최적 해법으로부터 큰 문제의 최적 해법을 구할 수 있음
      - 동적 계획법과 그리디 알고리듬의 유용성 판단에 사용
      - 강화 학습에서 흔히 등장하는 벨만 방정식도 이에 기초
      - 예 : 최단 경로 찾기
    - 2. 하위 문제의 반복
      - 똑같은 평가를 반복해야 함
      - 하위 문제의 크기가 작아야 함
      - 예 : 피보나치 수열

<br/>

  - 분할 정복 vs 동적 계획법
    - 분할 정복
      - 큰 문제를 하위 문제로 나눔
      - 하위 문제의 최적의 해법을 합침
      - 반복되지 않는 하위 문제
    - 동적 계획법
      - 큰 문제를 하위 문제로 나눔
      - 하위 문제의 최적의 해법을 합침
      - 반복되는 하위 문제
  - 병합 정렬이 동적 계획법이 아닌 이유
    - 대표적인 분할 정복 알고리듬
    - 재귀적으로 하위 배열을 정렬한 뒤 병합함
    - 각 하위 배열은 다름(반복되지 않음!), 따라서 동적 계획법이 아님. 퀵정렬도 마찬가지!
  - 동적 계획법으로 문제를 푸는 과정
    - 1. 문제에 동적 계획법을 사용할 수 있는지 판단
    - 2. 상태와 매개변수를 결정
    - 3. 상태 간의 관계를 정립
    - 4. 종료조건을 결정
    - 5. 메모이제이션 혹은 타뷸레이션을 추가
  - 동적 계획법을 적용 가능한 문제 판단하기
    - 보통 이런 패턴
      - 어떤 제약 하에 어떤 값을 최적화(최대/최소)
      - 재귀 함수에 동일한 매개변수가 반복적으로 전달되는 경우
    - 그리드를 만들려 해볼 것
      - cell 안의 값이 보통 최적화하려는 값
      - 문제를 하위 문제로 어떻게 나눌지 생각할 것(각 cell이 하위 문제)
      - 그러면 그리드의 x/y축을 결정하는데 도움이 될 것임
  - 동적 계획법으로 풀 수 있는 문제
    - 최단 경로 찾기(다익스트라 알고리듬)
    - 최장 공통부분 문자열
    - 와일드카드 패턴 매칭
    - 부분집합 합
    - 레벤슈타인 거리(편집 거리)
    - 연속 행렬 곱셈
    - 등 다수

<br/>

~~~c#
// 동적 계획법을 사용한 배낭 문제

namespace ConsoleApp1
{
    public class Program
    {
        static int getMaxValue(int numSpace, Item[] items)
        {
            int numItems = items.Length;

            int[,] cache = new int[numItems, numSpace + 1];

            for (int s = 1; s <= numSpace; ++s)
            {
                if (items[0].space > s)
                {
                    continue;
                }

                cache[0,s] = items[0].value;
            }

            for (int i = 1; i < numItems; ++i)
            {
                for (int s = 1; s <= numSpace; ++s)
                {
                    int space = items[i].space;
                    int value = items[i].value;

                    if (space > s)
                    {
                        cache[i,s] = cache[i - 1,s];
                    }
                    else
                    {
                        cache[i,s] = Math.Max(cache[i - 1,s], cache[i - 1,s - space] + value);
                    }
                }
            }

            return cache[numItems - 1,numSpace];
        }

        static void Main(string[] args)
        {
            Item[] items = new Item[]
            {
                new Item { space = 5, value = 3 },
                new Item { space = 12, value = 9 },
                new Item { space = 2, value = 1 },
                new Item { space = 4, value = 5 },
                new Item { space = 9, value = 7 }
            };

            int numSpace = 15;

            int result = getMaxValue(numSpace, items);

            Console.WriteLine(result);
        }
    }

    public class Item
    {
        public int space { get; set;}
        public int value { get; set;}
    }

}
~~~


###### [동적 계획법](#동적-계획법)
###### [Top](#top)

<br/>
<br/>

***

# 그리디(greedy, 탐욕) 알고리듬
  - 그 순간 최적(locally optimal)의 해법을 찾는 방법
    - 미래를 전혀 생각하지 않음
    - 탐욕에 눈이 멀면 이렇게 행동한다고 해서 붙은 이름
  - 최종적으로 최적(globally optimal)해법이 안 나올 수도 있음
    - 그러나 충분히 괜찮은 해법인 경우가 많음
    - 빠른 의사 결정이 가능
  - 근사(approximation)알고리듬
  - 그리디하게 푸는 배낭 알고리듬
    - 탐욕의 기준에 따라 여러 가지 방법이 가능
      - 1. 가장 비싼 물건부터 훔친다
      - 2. 제일 작은 물건부터 훔친다
      - 3. 단위 면적당 값어치가 가장 높은 물건부터 훔친다
        - 단위 면적당 값어치 : 값어치/공간
  - 그리디 알고리듬의 장점
    - 최종적으로 최적인 해법을 못찾을 수도 있지만 충분히 훌륭한 결정을 빨리 내릴 수 있음
      - 보통 랜덤하게 선택하는 것보다 나음
      - 수백 개의 물건을 훔쳐야 한다면?
        - 1. 정렬 : O(nlogn)
        - 2. 순서대로 훑음 : O(n)
        - 즉, O(nlogn)이 된다

<br/>

  - 쪼갤 수 있는 배낭 문제
    - 이전에 본 배낭 문제는 0-1 배낭 문제
      - 물건을 훔치거나 안 훔치는 것만 가능
    - 문제에 따라 일부만 취할 수 있는 경우도 있음
      - 예 :  케이크를 절반만 잘라 훔치기
    - 이걸 쪼갤 수 있는 배낭 문제라고 함
    - 그리디 알고리듬이 최적이 해법을 찾는다!
      - 단위 면적당 값어치가 가장 높은 것부터 가져가면 된다!

<br/>

  - 그리디 알고리듬을 사용하기 적합한 경우
    - 제대로 된 해법을 구하는 알고리듬의 복잡도가 너무 높은 경우
    - 적당히 좋은 해법도 상관없는 경우
    - 동적 계획법을 사용할 수 없는 경우
      - 즉, 중복되는 하위 문제가 없음
  - 그리디 알고리듬을 사용할 수 있는 경우
    - 1. 최적 부분구조
    - 2. 그리디 선택 속성 :  한번 내린 결정은 다시 돌아보지 않음
      - 과거의 선택 : 현재 선택에 영향을 미칠 수 있음
      - 미래의 선택 : 현재 선택에 영향을 안 미침
    - 몇 가지 팁
      - 보통 최소/최대화 문제
      - 여러 그리디 선택이 가능하면 모두 시도 혹은 반례를 통해 제기할 것
      - 정렬을 해야 속도가 빨라질 수도 있음
  - 그리디 접근법으로 풀 수 있는 문제
    - 인터벌 파티셔닝
    - 지연 시간 최소화
    - 다익스트라의 최단 경로
    - 운영체제의 job 스케줄링
    - k-센터 문제
    - 결정 트리 학습법
    - 허프만 코딩
    - 외 다수

<br/>

  - 데이터 압축
    - 원본 데이터보다 적은 비트 수로 정보를 표현하는 방법
    - 주 용도
      - 저장공간 절약
      - 전송속도 단축
  - 몇 가지 압축 파일 포맷
    - 무손실
      - 원본 데이터를 완전 복구 가능
      - 비교적 압축 파일 크기가 큼
      - 데이터 분석을 통한 알고리듬 개발
      - 종류
        - ZIP
        - RLE
    - 손실
      - 원본 데이터와 비슷하게만 복구(사람은 차이를 못 느낄 수도 있음)
      - 비교적 압축 파일 크기가 작음
      - 데이터 분석을 통한 알고리듬 개발
      - 인간의 이해를 통한 알고리듬 개발
      - 종류
        - JPEG
        - MP3
  - 양자화(quantization)
    - 원본에서 비슷한 값들을 합쳐 값의 개수를 줄이는 방법
    - 따라서 값 표현에 사용하는 비트 수를 줄일 수 있음
    - 연산 자체는 매우 간단
    - 품질 손상을 최소화할 수 있는 방법 고안이 중요
      - 예) JPG는 주파수 데이터로 바꾼 뒤 양자화
      - 예) DXT1 이미지는 4X4블록마다 16비트 RGB 5:6:5 색상 둘을 사용
      - 예) 보간(interpolation)

<br/>

  - 문자열 전송하기
    - 문자열을 전송하기 위해서 문자열을 이진수로 표현해야 함
    - 압축 방법
      - 허프만 코딩(Huffman coding) = 팔레트를 이용한것
        - 입력 문자들에 적합한 가변 부호(code)를 선택하는 알고리듬
        - 최적 접두어 코드를 사용
          - 헷갈리지 않고 각 코드를 제대로 된 문자로 디코딩 가능
          - 어떤 문자에 할당된 코드는 다른 문자에 할당된 코드의 접두어가 아님
        - 허프만 코딩은 그리디 알고리듬 이다
      - 허프만 코드로 인코딩 하기
        - 문자중 가장 많이 쓰는것은 1, 그다음은 01, 그다음은 001, 그다음은 0001 … 마지막은 0000 으로 인코딩 한다
      - 허프만 디코딩
        - 인코딩 된 메시지의 비트를 순서대로 고려
        - 1. 트리에서 비트 값과 일치하는 변을 따라감
        - 2. 리프 노드에 도달하지 않았다면 1로 돌아감
        - 3. 리프 노드에 있는 문자를 출력 후 루트 노드로 복귀
        - 4. 모든 비트를 읽지 않았다면 1로 돌아감
      - zip파일도 허프만 코딩으로 압축한다!

###### [그리디(greedy, 탐욕) 알고리듬](#그리디greedy-탐욕-알고리듬)
###### [Top](#top)

<br/>
<br/>

***

# 그래프
  - 데이터들을 잘 정리하는 방법 중 하나
    - 데이터 == 노드
    - 잘 정리하는 == 노드 간의 관계를
    - 예시	
      - 지하철 노선표
      - 선수과목
      - 동료들의 관계
      - 세탁기 사이클
      - 스킬 트리
      - 등등
      - 그냥 어떤 노드간의 관계를 나타낸 것이 그래프이다
    - 트리와 매우 유사한 것처럼 보이는데, 트리가 사실은 그래프의 특수화된 모습이다. 트리는 방향비순환그래프(DAG, directed acyclic graph) 중 하나이다.
    - 모든 자료구조들을 그래프로 나타낼 수 있다. 그래프는 모든것에서 가장 추상적이고 일반화된 모습이다.

<br/>

  - 그래프의 정의와 용도
    - 데이터들과 그 관계를 보여주는 방법 중 하나
    - 서로 연관 있는 노드의 집합
    - G = (N, E)의 의미 -> 그래프는 노드들의 집합N과 변들의 집합E 가 그래프이다
    - 네트워크 형태의 관계를 보여주기에 적합
    - 복잡한 실세계의 문제를 모델링하기에 적절
      - 네트워크 형태가 명백하게 안 보이는 경우도 있음
      - 그래프 이론을 적절히 적용하면 시간 복잡도를 확연히 줄일 수도 있음
  - 그래프 관련 용어
    - 노드(정점, 꼭지점)
    - 변(간선, 선)
    - 차수(노드에 나가거나 들어오는 선들)
    - 루프

<br/>

  - 그래프의 종류
    - 방향/무방향 그래프
      - 방향 그래프
        - 변이 한 방향만 가리킴
        - 꼬리 -> 머리로 이동은 가능
        - 머리 -> 꼬리로 이동은 불가능
      - 무방향 그래프
        - 변에 특별한 방향이 없음
        - 따라서 양방향을 가리키는 것과 같음
        - 꼬리 -> 머리, 머리 -> 꼬리 모두 가능
        - 무방향 그래프의 최대 변 개수
          - 모든 노드가 연결되어 있는 경우
            - 단, 평행 변 이나 루프는 없음
          - 첫 번째 노드의 변 : N - 1개
          - 두 번째 노드의 변 : N - 2개(중복된 것을 다시 세지 않음)
          - 세 번째 노드의 변 : N - 3개
          - 2분의 n(n-1)
  - 순환/비순환 그래프
    - 비순환 그래프
      - 일단 떠나면 그 노드로 돌아오는 경로가 없음
      - 그래프 안의 모든 노드에 대해
    - 순환 그래프
      - 떠난 뒤에도 그 노드로 돌아오는 경로가 있음
      - 그런 노드가 하나만 있어도 순환 그래프
  - 가중/비가중 그래프
    - 비가중 그래프
      - 모든 변이 동일한 의미를 가짐
      - 각 변의 값이 같음
      - 별도의 표기 불필요
    - 가중 그래프
      - 각 변의 관계 정도가 다름(예 : 거리, 시간)
      - 각 변의 값이 다름
  - 방향 비순환 그래프, 방향 가중 그래프 등 다양한 그래프의 종류를 합칠 수가 있다

<br/>

  - 그래프의 다양한 표현 방법
    - 1. 원과 선
      - 사람이 가장 이해하기 쉬운 표현법
      - 한눈에 그래프를 파악 가능
      - 단, 노드와 변의 수가 적당해야 함
      - 굳이 코드로 표현하면 트리와 비슷한 구조
      - 하지만 대규모 데이터 처리에 적합한 표현법은 아님
    - 2. 인접 행렬
      - N x N 행렬
        - G[N][N]
        - N : 그래프 G안에 있는 노드 수
      - 서로 인접한 노드를 표현
        - 인접 : 두 노드 사이를 연결하는 변이 있음
        - i에서 j로 향하는 변이 있다면 G[i][j] = 1
        - 없으면 G[i][j] = 0
      - G가 가중 그래프이면 0 / 1 대신 실제 가중치를 저장
      - 인접 행렬의 장점
        - 일단 알면 쉽게 구현 가능
        - 변 제거의 시간 복잡도가 O(1)
        - 다음과 같은 관계를 효율적으로 찾음
          - 노드 a에서 b로 가는 변이 존재하는가?
          - O(1)
      - 인접 행렬의 단점
        - 공간을 더 차지함 O(N²)
        - 언제나 같은 공간을 차지
          - 연결된 노드가 많아도
          - 연결된 노드가 적어도
        - 인접 행렬을 만드는 시간은 O(N²)
        - 인접 노드를 찾는 시간은 O(N)
    - 3. 인접 리스트
      - 각 노드마다 이웃의 리스트를 만듦
        - 리스트 N개
        - 보통 연결 리스트 N개를 배열에 저장
        - 연결 리스트 대신 다른 자료구조도 사용가능
      - 원과 선을 굳이 코드로 구현한 것과 큰 차이 없음
      - 인접 리스트의 장점
        - 공간을 적게 사용
        - 삽입/삭제가 빠름
      - 인접 리스트의 단점
        - 다음과 같은 관계를 찾는 게 느림
          - 노드a에서 b로 가는 변이 존재하는가?
          - O(1)보다 느림

<br/>

  - 인접행렬

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/685abd9a-e388-4af3-801b-db2be7f32266)

###### [그래프](#그래프)
###### [Top](#top)

<br/>
<br/>

***

# 그래프 깊이 우선 탐색(DFS)
  - 그래프의 깊이 우선 탐색(DFS)
    - 트리에서 사용했던 알고리즘을 그래프 에서도 사용할 수 있다 “깊이 우선 탐색(DFS)”
    - 깊이 우선 탐색을 하면 트리에서는 잘 되지만, 그래프에서는 무한 루프가 생길 수 있다. 그래프에서는, 트리의 알고리즘에서 이미 방문한 노드는 처리하지 않게 하는 로직을 추가하면 된다
    - 무한 루프의 해결법
      - 이미 처리했던 노드를 다시 처리하면 안됨
      - 방문했던 노드를 기억할 방법이 필요
        - 1. 스택에 이미 들어간 노드는 다시 안 넣음
        - 2. 스택에서 pop()을 한 후에 이미 방문했던 노드인지 확인
      - 두 번째 방문 시 처리 안 하고 곧바로 다음 노드로 넘어감
    - 방향 그래프는 모든 노드를 방문하지 못할 수 있다. 트리 같은 경우는 하나의 루트 노드에서 그 밑으로 모든 노드가 시작된다는 것이기 때문에 가능하지만 그래프는 루트노드 같이 특수한 노드가 없음
      - 루트 : 모든 노드와 직간접적으로 연결되는 노드
      - 방향 그래프, 끊어진 노드 때문
    - 일반적인 DFS는 모든 노드를 방문하지 못할 수 있음
    - 해결책 : DFS의 인자로 모든 노드 목록을 전달
      - 각 노드를 기점으로 DFS를 한 번씩 실행하는 것과 마찬가지
     - 단, 방문 목록을 공유하기에 중복 방문은 없음
    - 후위 순회 DFS
      - 그래프의 각 노드에 대해
      - 1. DFS 함수를 호출
        - 현재 노드를 발견한 것으로 표시
        - 처음 발견한 이웃 노드마다 DFS를 호출
      - 2. 현재 노드를 방문
    - 전부 O(N+E) 시간 복잡도를 가짐

<br/>

  - 위상 정렬(topological sort)
    - 그래프의 노드를 선형으로 정렬하는 방법
    - 우선순위가 바뀌지 않음
      - 예 : B노드를 가리키던 모든 노드들이 B보다 전에 나옴
    - DAG만 유효한 위상 정렬이 가능
      - 순환(cycle)하는 노드가 있다면 우선순위 판단이 불가능
      - 시작점이 존재해야 함
    - 해답이 여럿일 수 있음
    - 위상 정렬 알고리듬
      - 몇 가지 알고리듬이 존재
        - 깊이 우선 탐색(DFS)
        - 칸 알고리듬(kahn’s algorithm)
      - 크게 두 가지 용도
        - 실제로 위상 정렬을 함
        - 위상 정렬 가능한 그래프인지 판단
    - 위상 정렬을 DFS를 사용해서 후위 순회를 한뒤, 거꾸로 뒤집으면 끝이다!
    - 위상 정렬의 용도
      - 관계에서 순서를 정하는 매우 많은 곳에 사용 가능
        - 프로젝트 일정 만들기
        - CPU명령어 실행 순서 결정
        - 스프레드 시트 셀 평가 순서 결정
        - 컴파일 순서 결정
        - DB테이블 로딩 순서 결정
        - 선수 순위 결정

<br/>

  - 강한 결합 요소(SCC)
    - 방향 그래프에서 끈끈한 관계를 가지는 노드들의 최대 그룹
      - 그 그룹에 속한 두 노드는 어떻게든 연결되어 있음
      - 반드시 이웃은 아님
    - 정의
      - C에 속한 모든 정점 쌍 u, v에 대해 u -> v, v -> u인 가장 큰 집합
    - SCC의 주용도는 회적화
      - 다른 알고리듬에서 고려해야 할 정점 수를 줄여줌
    - 위상 정렬과 SCC
      - 순한 그래프는 위상 정렬이 불가능
      - 순환하는 노드들은 SCC
      - SCC로 치환한 그래프는 DAG
        - 이제 위상 정렬 가능!
      - 위상 정렬을 하기 위해 SCC를 사용하는 일이 흔함
    - 강한 결합 요소 알고리듬
      - DFS기반 알고리듬
        - 코사라주 알고리듬
        - 타잔 알고리듬
        - 경로 기본 알고리듬
      - 도달 가능성 기반 알고리듬(분할 정복)

###### [그래프 깊이 우선 탐색(DFS)](#그래프-깊이-우선-탐색dfs)
###### [Top](#top)

<br/>
<br/>

***

# 그래프 너비우선 탐색(BFS), 최단경로
  - 그래프의 너비 우선 탐색
    - 트리에서 사용했던 알고리즘을 그래프 에서도 사용할 수 있다  “너비 우선 탐색(BFS)”
    - 방문했던 노드를 기억할 방법이 필요
    - 전부 O(N+E) 시간 복잡도를 가짐

<br/>

  - 최단 경로(shortest path)
    - 가장 간단한 방법은 주먹구구식
      - 모든 가능한 조합을 만든 뒤, 그중 가장 짧은 것을 선택
      - 단, 순환이 없게끔 해야함
    - BFS를 사용하면 최단 경로를 찾을 수 있음
      - 시간 복잡도 O(N+E)
    - BFS가 최단 경로를 찾는 이유
      - 현재 깊이의 모든 노드를 방문 후 다음 깊이로 진행
        - 깊이 n-1에서는 d노드를 찾지 못했음
        - 깊이 n을 뒤지다 보면 d노드를 찾음
      - 따라서 BFS는 언제나 최단 경로를 찾음
    - BFS로 최단 경로 찾기
      - 기본적인 BFS와 크게 다르지 않음
      - 그러나 시작점부터 현재 노드까지의 거리를 기억해야 함
        - 거리 = BFS 깊이
      - 최종 노드부터 반대 방향으로 추적
      - 추적을 위해 추가 정보 필요
        - 선행 노드 : 누가 나를 큐에 넣었는가?
        - 큐에 다음 노드는 넣을 때 선행 노드도 같이 기재

<br/>

  - 다익스트라 알고리듬(Dijkstra’s alorithm)
    - 각 변의 거리가 다른 최단 경로 찾기
      - BFS로 간단히 해결할 수 없음
        - 가중 그래프
        - BFS의 깊이 != 거리
    - 두 노드 사이의 최단 경로를 찾음
    - 방대한 노드 네트워크에 사용하기 충분히 빠름
    - 변의 가중치가 음수인 경우에는 제대로 작동하지 안흥ㅁ
    - 실세계에서 많이 사용
      - 지도/내비게이션
      - IP라우팅
      - 경유 항공편 찾기
      - 등
    - 다익스트라 알고리듬의 기초
      - 모든 노드를 한 번씩 방문하며 아래의 연산을 함
        - 1. 아직 방문 안 한 노드 중 가장 가까운 노드 n을 선택
        - 2. n의 각 이웃 노드 m으로 여행하는 거리를 계산(n의 거리 + n -> m 거리)
        - 3. 이 결과가 m의 기존 거리보다 가까우면 m의 거리를 업데이트
      - 모든 노드를 방문하면 최단 거리를 찾음
        - 모든 노드를 거쳐 온 경로 중 최솟값을 취했기 때문
      - 다익스트라는 동적 계획법(DP)이다!!
    - 다익스트라 알고리듬설명
      - 1. 아직 방문 안 한 노드 중 가장 거리 값이 작은 노드 n을 선택
      - 2. n의 각 미방문 이웃 m으로 가는 더 짧은 경로가 있다면 업데이트
      - 3. 다음 조건 중 하나를 만족하기 전까지 1~2를 반복
        - 모든 노드를 방문했음
        - n이 목적지임
      - 4. 목적지까지의 거리/경로를 반환
    - 인접 행렬을 사용하려고 하면 몇가지 문제가 생긴다
      - 행과,열로 저장하기 때문에 공간 복잡도도 N²이 되고, 시간 복잡도도, 그 것을 전부 방문해야 하는 상황이 생길 수 있기 때문에 N²이 될 수 있다
      - 이럴때는 어쩔 수 없이 인접 리스트로 만드는것이 좋다
    - 시간 복잡도
      - 방문하는 노드 수(=알고리듬 실행 횟수) : N
      - 최소 거리 노드 선택 : N -> N보다 더 빠르게 만들 수 있다 우선순위 큐로 logN으로!
      - 모든 변을 한 번씩은 지나감 : E
        - 거리 값 업데이트 : 1 -> 최소 거리 노드를 빠르게 하기 위해 우선순위 큐를 사용하게 되면 O(1)이 아닌 logN이 된다
      - O(N² + E) = O(N²) -> O(NlogN + ElogN) = O((N+E)logN)

<br/>

  - A* 알고리듬
    - 다익스트라와 기본은 같은 알고리듬
    - 하지만 쓸데 없는 평가를 피할 수 있음
    - 예 : 서울에서 부산가기
      - 다익스트라 : 경부선, 호남선, 경인선, 등등 모두 탐색
      - A* : 경부선만 따라 쭉 달림
    - 이를 위해 다음 노드 선택 시 기준을 하나 더 추가
      - 다익스트라의 기준은 시작점부터 노드까지의 거리
      - A*가 추가하는 기준은 그 노드로부터 목적지까지의 거리
    - 현재 노드부터 목적지까지의 거리
      - 목적지까지 탐색을 다 하기 전까지는 확실히 모름
      - 따라서 A*가 추가한 기준은 결정적이 아님
        - 휴리스틱
        - 근사치
      - 이 휴리스틱 함수에 따라 A*의 성능이 달라짐
      - 대부분의 경우 다익스트라 보다 빠름
        - 실세계의 대표 경로 찾기 알고리듬이 A*인 이유
        - 하지만 데이터 따라 느릴 수도 있음
    - A*의 두 가지 노드 선택 기준
      - g(n) : 시작 노드부터 노드 n까지의 거리(실제 값)
      - h(n) : n부터 목적지 노드까지의 거리(추정치)
      - f(n) : 시작 노드부터 목적지 노드까지의 거리(추정치)
        - f(n) = g(n) + h(n)
      - 다음 노드 선택 시
        - 다익스트라는 g(n)이 최소인 것을 선택
        - A*는 f(n)이 최소인 것을 선택
    - A*의 h(n)
      - 계속 목적지 방향으로 나아가고 싶음
      - 목적지 쪽에 있는 노드를 우선적으로 선택하고 싶음
      - 목적지 쪽에 있는 노드의 h(n)이 더 작아야 함
      - 목적지에 가까운 노드의 h(n)이 더 작아야 함
      - 즉, h(n)은 거리 함수!
        - 모든 상황에 최고인 함수는 없음
        - 상황에 따라 선택
      - h(n)의 결과와 실제 결과의 관계에 따라 A* 알고리듬이 행동이 바뀜
      - h(n)이 언제나 0인 경우는 , A*가 다익스트라 알고리듬과 똑같이 동작한다
    - A*가 중복 방문을 허용하는 이유
      - 다익스트라는 새로 방문하는 노드의 실제 거리가 최소
        - 실제 거리 g(n)만 노드를 뽑는 기준으로 사용하기 때문
        - 이미 최소기에 더 이상 작아질 수 없음
      - A*는 새로 방문하는 노드의 거리가 실제 거리가 아님
        - h(n)으로 추정하는 부분이 있음
        - 지금 최소 거리라 믿고 뽑는 노드가 실제로는 최소가 아닐 수 있음
        - 나중에 다른 경로를 통해 방문하면 거리가 작아질 수도 있음
        - h(n)이 특정 조건을 만족하면 노드를 한 번씩만 방문함
          - 일관적, 단조로운 휴리스틱

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/4e6d45ea-391d-4edd-8ac0-7c8232cc5dd9)

<br/>

  - 최단 경로 : 단일 출발지 vs 모든 쌍
    - 단일 출발지 최단 경로(SSSP)
      - 한 노드에서 시작해서 다른 모든 노드로 향하는 최단 거리를 찾음
      - 다익스트라, A*
    - 모든 노드 쌍에 대해 최단 경로를 찾는 문제들도 있음
      - APSP
      - SSSP알고리듬을 모든 노드에서 한번씩 시작해도 해법은 나온다
        - 하지만 시간 복잡도가 SSSP알고리듬 시간 복잡도의 N배
        - 더 나은 APSP전용 알고리듬이 있다
      - 플로이드 워셜(Floyd-Warshall) 알고리듬

<br/>

  - 플로이드 워셜(Floyd-Warshall)
    - 모든 쌍의 최단 거리를 찾는 알고리듬 중 하나
    - 다익스트라와 달리 인접 행렬(2D)을 사용
    - 다익스트라와 마찬가지로 동적 계획법 알고리듬
    - 기본 원리
      - u -> v가 최단 경로인 경우, 중간에 거쳐가는 m노드에 대해 u -> m, m -> v모두 최단 경로
    - 그래프에 있는 노드를 1~N까지 번호를 매김
    - sp를 다음과 같이 정의
      - i -> j의 최단 경로
      - 중간에 1~k노드를 거쳐도 됨
    - sp(i, j, k)는 sp(i, j, k-1)의 확장
      - sp(i, j, k-1) : 1~k-1 노드를 거칠 수 있는 i -> j 최단 거리
      - sp(i, j, k) : sp(i, j, k-1)에 추가적으로 k노드도 거치는 경우도 고려
        - 1. 더 짧은 거리를 못 찾음(=기존 경로를 그대로 이용)
          - sp(i, j, k) = sp(i, j, k-1)
        - 2. 더 짧은 거리를 찾음(=k를 따라 이동해야 함)
          - sp(i,j,k) = sp(i,k,k-1) + sp(k,j,k-1)
    - 시간 복잡도
      - 2D배열을 흝어야 함
      - k마다 배열을 훑음
        - O(N³)

###### [그래프 너비우선 탐색(BFS), 최단경로](#그래프-너비우선-탐색bfs-최단경로)
###### [Top](#top)

***

# 그래프 알고리즘 다른것들
  - 신장 트리(spanning tree)
    - 어떤 그래프 안에 있는 모든 노드를 연결하는 트리
    - 당연히 그래프 안에 있는 변만 사용해야 함
    - 신장 트리는 여럿 있을 수 있음
  - 최소 신장 트리(minimum spanning tree)
    - 줄여서 MST라고 함
    - 신장 트리 중 비용이 최소인 트리
      - 비용 : 모든 변의 가중치를 합한 값
      - 최소 비용 신장 트리라고도 함
    - 최소 신장 트리에서 변의 개수 : N-1개
    - MST에서 사용하는 개념
      - 순환 : 반복되는 노드가 시작 노드 끝 노드뿐인 경로
      - 컷 : 어떤 그래프를 서로소인 두 하위 집합으로 나누는 행위
    - MST알고리듬의 기본 원리
      - 1. 그래프에 있는 노드 중 한 변을 확인
      - 2. 이 변이 MST에 들어가야 하는지 검사
        - 이때, cut property를 사용
        - 들어가야 하면 MST에 추가, 아니면 무시
      - 3. MST의 모든 변을 찾지 못했다면 1로 돌아감
    - 대표적인 MST알고리듬
      - 크러스컬 알고리듬
      - 프림 알고리듬
  - 크러스컬 알고리듬
    - 1. 그래프의 각 노드마다 그 노드만 포함하는 트리를 만듦
    - 2. 모든 변을 가중치의 오름차순으로 정렬 -> S배열
    - 3. S가 비거나 MST가 완성될 때까지 다음의 과정을 반복
      - a) S에서 가중치가 가장 적은 변을 제거해서 고려
      - b) 이 변이 두 트리를 연결하는지 검사
        - 맞다면 MST에 추가
    - 서로소 집합 자료구조
      - 합집합 찾기 자료 구조라고도 함
      - 겹치지 않는 집합들을 저장하는 자료 구조
      - 서로 다른 트리는 겹치지 않는 집합
      - 이걸 서로소 집합에 저장하면 간단한 연산만으로 겹치는지 알 수 있음

<br/>

  - 외판원 문제
    - 줄여서 TSP라고 부름
    - 여러 도시를 방문해야 하는 외판원
    - 각 도시를 최소 한 번씩 방문해야 함
    - 가장 짧은 거리를 이동해서 다음을 완료해야 함
    - TSP알고리듬의 시간 복잡도
      - 주먹구구식 알고리듬 : O(N!)
        - 20개 노드만 되도 거의 사용 불가능
      - 헬드-카프 알고리듬 : O(N²2ⁿ)
        - 동적 계획법
        - 공간 복잡도 : O(2ⁿN)
      - 이 이상 빠른 알고리듬이 현존하지 않음, NP난해 문제
      - 그래서 TSP는 보통 근사 알고리듬으로 해결한다

<br/>

  - 등등 그 외의 수많은 알고리듬이 존재한다

###### [그래프 알고리즘 다른것들](#그래프-알고리즘-다른것들)
###### [Top](#top)

<br/>
<br/>
