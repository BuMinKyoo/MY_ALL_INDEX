<br/> 

###### Top

- [알고리듬이란, 효율성](#알고리듬이란-효율성)
- [기초 자료 구조와 시간 복잡도](#기초-자료-구조와-시간-복잡도)
- [재귀함수, 꼬리재귀함수](#재귀함수-꼬리재귀함수)
- [주먹구구식 알고리듬, P vs NP 문제](#주먹구구식-알고리듬-p-vs-np-문제)
- [탐색 알고리듬, 이진 탐색](#탐색-알고리듬-이진-탐색)
- [정렬 알고리듬(버블,선택,삽입,퀵,병합,힙)](#정렬-알고리듬버블선택삽입퀵병합힙)
- [해시 알고리듬](#해시-알고리듬)
- [암호화](#암호화)

<br/>
  
- [트리](#트리)
- [이진 탐색 트리](#이진-탐색-트리)
- [트리 순회(tree traversal)](#트리-순회tree-traversal)
- [레드-블랙 트리(red-black tree)](#레드블랙-트리redblack-tree)
- [트라이(Trie), 공간분할 트리](#트라이trie-공간분할-트리)
- [깊이 우선 탐색, 너비 우선 탐색, 미니맥스](#깊이-우선-탐색-너비-우선-탐색-미니맥스)
- [동적 계획법](#동적-계획법)
- [그리디(greedy, 탐욕) 알고리듬](#그리디greedy-탐욕-알고리듬)

<br/>

- [그래프](#그래프)
- [그래프 깊이 우선 탐색(DFS)](#그래프-깊이-우선-탐색dfs)
- [그래프 너비우선 탐색(BFS), 최단경로](#그래프-너비우선-탐색bfs-최단경로)
- [그래프 알고리즘 다른것들](#그래프-알고리즘-다른것들)

<br/>
<br/>

***

# 알고리듬이란, 효율성
  - 알고리듬이란?
    - 어떤 부류의 문제를 해결하는 컴퓨터로 구현 가능한 명백한 명령어들
    - 간단한 문제를 해결하는것도 전부 알고리듬이라고 할 수 있다!
    - 따라서 우리가 작성하는 거의 모든 코드는 알고리듬 이라고 할 수 있음
    - 하지만 사소한 코드는 보통 학계 및 실무에서 알고리듬이라 부르지 않음
    - 무엇을 알고리듬이라 하고 무엇을 아니라 하는지 명백한 기준은 없음
    - 사람들이 말하는 습관을 보고 익숙해져야 할 부분

<br/>

  - 훌륭한 알고리듬이 갖춰야할 자질
    - 입력과 출력이 명확히 정의되어 있어야 함
      - 입력은 시작 시 비어있을 수도 있음
    - 알고리듬의 각 단계가 명확하며 모호하지 않아야 함
    - 유한 시간 안에 결과가 나와야 함
    - 포팅이 가능한 의사코드 작성하기
      - 거의 모든 언어에 공통되는 연산만 사용하기
      - 결국 하드웨어와 기계어/어셈블리어 수준에서 지원하는 것들
      - 고수준 언어 중에는 C에서 지원하는 것 정도
      - 특정 언어에 있는 추상적으로 만들어진 것으로 알고리듬을 구현하면 보통 좋지 않다
  - 알고리듬 공부를 해도 안 느는 프로그래머들
    - 하드웨어가 어떤 연산을 지원하는지 모름
    - 이미 존재하는 마법 같은 함수만 호출해봄
    - 툭하면 언어 문법이 틀리는데 컴파일 오류를 봐도 그 문제를 못 찾음
    - 컴퓨터에 데이터가 어떻게 저장되는지 모름
    - 힙과 스택 메모리의 차이에 대해 모름
  - 알고리듬의 효율성
    - 자원의 효율적 사용을 뜻함
    - 자원
      - 시간 : CPU 속도 등
      - 공간/용량 : 메모리 사용량 등
    - 시간과 공간은 종종 상반 관계
    - 자원을 많이 사용할수록 그 알고리듬이 복잡하다고 말함
      - 시간 복잡도
      - 공간 복잡도
      - 알고리듬 복잡도를 표현하는 방법 중 하나 : 빅오 표기법
  - 알고리듬의 효율성 분석은 다소 추상적
    - 알고리듬 공부를 할 때는 하드웨어 차이에 신경을 안씀
      - 추상적인 기계에서 알고리듬을 실행한다 가정
        - 왜냐하면, 요즘 컴퓨터는 덧셈이 숫자가 커도 한번에 연산이 가능하지만, 예를들어 한번에 1씩 밖에 더하지 못하는 기계에서는 알고리듬 속도가 전혀 달라질 수 있기 때문에
      - 알고리듬 자체에 집중하도록 도와줌
    - 랜덤 접근 기계
      - 다양한 하드웨어를 일반적인 형태로 대표하는 가상의 기계
      - 레지스터를 갖춘 CPU 1개
      - 정수와 부동소수점 저장 가능
      - 메모리 간접 참조 지원
      - 캐시 메모리나 가상 메모리 등은 없음
  - 주의 : 알고리듬의 효율성과 실제 성능
    - 실제 코드 실행 속도는 하드웨어 따라 매우 달라질 수 있음
    - 따라서 실무에서는 효율성 낮은 알고리듬이 더 빠르기도 함
      - 실무에서는 현재 사용하고 있는 실제 하드웨어에서의 성능을 측정할것
    - 공부법
      - 알고리듬 공부를 통해 이론상의 성능에 대해 확실히 습득할 것
      - 하드웨어에 따라 달라지는 부분은 추가 지식으로 늘려나가면 됨

<br/>

  - 점근 표기법과 빅오 표기법
    - 점근 표기법(asymptotic notation)
      - 정수론과 해석학의 방법
      - 어떤 함수가 증가하는 모습을 다른 함수와 비교
      - 알고리듬의 복잡도를 논하거나 단순화시킬 때 사용
      - 대표적인 표기법
        - 대문자 O표기법(빅오 표기법)
          - 컴퓨터 공학에서는 주로 빅오 표기법을 사용함
        - 소문자 o 표기법
        - 대문자 오메가 표기법
        - 소문자 오메가 표기법
        - 대문자 세타 표기법
    - 빅오 표기법
      - 이름에서 알 수 있듯이 대문자 O를 이용해 표기
      - 주로 알고리듬을 분류하기 위해 사용
        - O(1), O(log n), O(n), O(nlog n), O(n²), O(n!)
    - 어떤 기준으로 분류 하는지?
      - 입력 데이터가 많아 짐에 따라 다음 둘이 얼마나 늘어나는지 측정
        - 실행시간(시간 복잡도)
        - 필요한 공간(공간 복잡도)

<br/>

  - O(1) 알고리듬
    - 입력 데이터의 크기 N에 상관없이 언제나 일정한 시간이 걸림
  - O(n) 알고리듬
    - 입력 데이터의 크기 N에 비례하는 시간이 걸림
  - O(n²) 알고리듬
    - 입력 데이터 크기 N의 제곱에 비례하는 시간이 걸림
  - O(log n) 알고리듬
    - O(1) 과 O(n) 사이
    - log는 2씩 곱해 나가는 것에 반대라고 생각하면 된다, 즉 분할 알고리즘 같은것 ^^
  - O(nlog n) 알고리듬
    - O(n) 과 O(n²) 사이

<br/>

  - ‘대략 그 정도’의 의미
    - 알고리듬의 실행 시간을 일반화하여 표현해서 쉽게 분류
      - 실행 시간 : 실행해야 하는 코드 단계 수
      - 실행 시간의 예 : 5n² - 5n + 3
      - 분류의 예 : O(n²) 알고리듬
    - 이 때 실행 시간 증가에 가장 큰 영향을 미치는 항만 사용해 일반화
      - 최고차항
    - 최고 차항에 붙은 계수도 무시

<br/>

  - 최선 vs 평균 vs 최악
    - 데이터에 따라 실제 알고리듬의 실행 속도가 달라질 수 있음
    - 데이터가 앞에 있냐 뒤에 있냐에 따라서 속도는 달라질 수 있음
    - 일반적으로 평균 시간을 시간 복잡도로 사용
  - O(1) < O(log n) < O(n) < O(nlog n) < O(n²) < O(2ⁿ) < O(n!)

###### [알고리듬이란, 효율성](#알고리듬이란-효율성)
###### [Top](#top)

<br/>
<br/>

***

# 기초 자료 구조와 시간 복잡도
  - 기초 자료 구조와 시간 복잡도(공간 복잡도는 다 O(n)이 된다)
    - 배열
      - 복잡도
        - 삽입 : 평균 O(N), 최악 O(N)
        - 삭제 : 평균 O(N), 최악 O(N)
        - 검색 : 평균 O(N), 최악 O(N)
    - 스택
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(1)
        - 삭제 : 평균 O(1), 최악 O(1)
        - 검색 : 평균 O(N), 최악 O(N)
    - 큐
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(1)
        - 삭제 : 평균 O(1), 최악 O(1)
        - 검색 : 평균 O(N), 최악 O(N)
    - 연결리스트
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(1)
        - 삭제 : 평균 O(1), 최악 O(1)
        - 검색 : 평균 O(N), 최악 O(N)
    - HashMap, Map, Dictionary
      - Key 와 Value 의 쌍으로 데이터를 저장하는 자료구조
    - Hashtable
      - Key를 Hash function에 집어 넣고, 그것을 배열의 고유한 index를 생성하고, 이 index를 활용해 값을 저장하거나 검색한다.
      - Value는 그 index에 해당하는 bucket, 즉 배열에 들어간다
      - 복잡도
        - 삽입 : 평균 O(1), 최악 O(N)
        - 삭제 : 평균 O(1), 최악 O(N)
        - 검색 : 평균 O(1), 최악 O(N)
    - 트리
    - 그래프

###### [기초 자료 구조와 시간 복잡도](#기초-자료-구조와-시간-복잡도)
###### [Top](#top)

<br/>
<br/>

***

# 재귀함수, 꼬리재귀함수
  - 재귀함수
    - 큰 문제를 반복 적용 가능한 작은 문제로 나뉘 푸는 방법
    - 어떤 함수가 매개변수만 바꾸어 자기 스스로를 호출하는 방식으로 구헌
  - 재귀함수의 장점
    - 가독성이 좋음
    - 코드가 짧음
    - 각 단계의 변수 상태가 자동 저장됨
    - 코드 검증도 쉬움
  - 재귀함수의 단점
    - 재귀적 문제 분석/설계가 안 직관적
    - 맹목적인 믿음이 필요
    - 스택 오버플로 발생 가능
    - 함수 호출에 따른 과부하

<br/>

  - 기본적으로 재귀 함수를 사용하는 게 나은 방법
    - 가독성이 좋고 유지보수가 쉬운 코드가 더 중요
  - 다음과 같을 경우 반복문으로 변환
    - 스택 오버플로가 날 가능성이 있는 경우
    - 성능 문제가 일어날 가능성이 큰 경우
    - 성능 문제가 확인된 경우
  - 모든 재귀 함수는 반복문으로 작성 가능
    - 복잡한 경우 스택 등의 데이터 구조를 사용해야 함

<br/>

  - 꼬리 호출(tail call)
    - 함수 코드 제일 마지막에서 다른 함수를 호출하는 경우
    - 그 후에 실행하는 명령어가 없음
  - 스택 프레임이 존재하는 이유
    - 함수에서 사용 중인 변수 값을 유지하기 위해
    - 타 함수 호출 후 반환되면 스택에 저장했던 값을 되돌려 사용
  - 꼬리 호출의 경우는 타 함수로부터 반환 후 더 이상 연산이 없음
    - 곧 바로 호출자로 반환
  - 따라서 스택 프레임에 저장해 놓은 변수 값을 재사용하지 않음
    - 이런 경우 컴파일러가 스택 프레임을 따라 안 만들고, 그냥 함수를 2개 따로 호출하는 것으로 만들기도 한다

<br/>

#ConsoleApp.cpp
~~~c#
public int sum()
{
  … 
  
  return sumsum();
}
~~~

<br/>

  - 꼬리 재귀(tail recursion)
    - 꼬리 호출의 특수한 경우
    - 마지막에 호출하는 함수가 자기 자신
    - 꼬리 호출과 똑같은 최적화가 적용됨

<br/>

#ConsoleApp.cpp
~~~c++
// 일반 재귀 함수
#include <iostream>

int factorialRecursive(int n)
{
    if (n <= 1)
        return 1;

    return n * factorialRecursive(n - 1);
}


int main()
{
    int n = factorialRecursive(4);
    std::cout << n << std::endl;
}
~~~

<br/>

#ConsoleApp.cpp
~~~c++
// 꼬리 재귀 함수
#include <iostream>

int factorialRecursive(int n, int fac)
{
    if (n <= 1)
        return fac;

    return factorialRecursive(n - 1, n * fac);
}

int factorial(int n)
{
	return factorialRecursive(n, 1);
}

int main()
{
    int n = factorial(4);
    std::cout << n << std::endl;
}
~~~

<br/>

  - 꼬리 재귀 함수 작성하기
    - 보통 꼬리 재귀 함수가 덜 직관적
    - 그러나 이런 식으로 작성된 코드가 종종 보임
    - 가장 큰 이유는 앞에서 말했던 최적화
    - 하지만 꼬리 호출 최적화를 지원 안 하는 언어라면?
      - 안 돼도 충분한 의미가 있음
      - 꼬리 재귀는 반복문으로 쉽게 변경 가능
    - 일반 재귀 함수보다 꼬리 재귀 함수가 더 좋은 이유
      - 일반 재귀 함수일 경우 재귀 할 때마다 메모리 스택에 함수 실행을 위해 할당하게 되고 이를 반복하게 되서 더이상 메모리 스택에 할당할 수 없을 때 스택 오버 플로우 등의 문제가 발생하는걸 방지할 수 있다
        - 재귀 할 때마다 이전 함수에서 할당한 메모리를 반납하기 때문
      - 꼬리 재귀 함수인지 판단하는 방법으로 함수 실행이 끝날 때 할당된 메모리가 없다면 꼬리 재귀고, 여전히 메모리를 할당받고 있다면 꼬리 재귀가 아닌 일반 재귀로 생각할 수 있다
    - 보통 debug모드에서는 TCO최적화를 해주지 않기 때문에 할 수 없지만, release모드 및 최적화 옵션을 최대로 키면 컴파일러가 해주기 때문에 확인 할 수 있다.
      - 언어 단에서 지원하지 않을 수도 있음

<br/>

#ConsoleApp.cpp
~~~c++
#include <iostream>

// 일반 재귀
int SumRecursive(int n)
{
    if (n <= 1)
        return n;

    return n + SumRecursive(n - 1);
}

// 꼬리 재귀
int SumRecursiveTail(int n, int fac)
{
    if (n <= 1)
        return n + fac;

    return SumRecursiveTail(n - 1, n + fac);
}
int Sum(int n)
{
	return SumRecursiveTail(n, 0);
}


int main()
{
    int n = SumRecursive(100000); // 스택오버 플로우가 발생함

    int n2 = Sum(100000); // 스택오버 플로우가 발생하지 않음

    std::cout << n << std::endl;
    std::cout << n2 << std::endl;
}
~~~

###### [재귀함수, 꼬리재귀함수](#재귀함수-꼬리재귀함수)
###### [Top](#top)

<br/>
<br/>

***

# 주먹구구식 알고리듬, P vs NP 문제
  - 주먹구구식(brute-force) 알고리듬
    - 모든 가능한 경우의 수를 시도하는 알고리듬
    - 좋은 알고리듬의 조건 중 ‘효율성’을 고려하지 않은 알고리듬
    - 보통 가장 직관적인 문제 해결법
    - 간단한 주먹구구식 알고리듬의 예
      - 배열에서 어떤 값의 첫 번째/마지막 색인 찾기
      - 배열에 들어있는 정수들의 합 또는 평균 구하기
      - 배열에서 최솟값이나 최댓값 찾기
      - char[ ]에 저장된 문자열 뒤집기(사본 생성 금지)
      - 등 등
    - 주먹구구식 알고리듬과 시간 복잡도
      - O(N) 보다 시간 복잡도가 높은 알고리듬들이 많음
      - 컴퓨터에서 실행하기에는 너무 느린 알고리듬들도 많음
        - 알려진 최적화 방법이 없는 것들도 존재
        - 반드시 나쁜 일은 아님
        - 보안 분야가 이에 많이 의존

<br/>

  - P vs NP 문제
    - 학문적으로 꽤 재밌는 논의가 있었던 부분
    - 아직까지 풀리지 않은 미해결 수학 문제 7개 중 하나
풀리면 21세기 사회에 가장 크게 공헌할 수 있는 문제 중 하나
  - P분류(P class)
    - 판정 문제들을 분류하는 방법 중 하나
      - 판정 문제 : 입력 값에 대해 예/아니오 답을 내릴 수 있는 문제
    - 결정론적 튜링 기계에서 다항식 시간 안에 풀 수 있는 모든 문제를 포함
    - 결정론적 튜링 기계
      - 튜링 기계 : 무언가를 계산하는 기계를 대표하는 가상의 장치
        - 일반적인 컴퓨터 알고리듬을 수행할 수 있음
      - 결정론적 튜링 기계란?
        - 어떤 명령어 실행 뒤, 다음 실행할 명령어가 확정됨
        - 코어 하나에서 명령어를 순서대로 실행한다 생각할 것
        - 즉, 코어 하나에서 실행되는 다항식 시간 알고리듬이 있는 문제는 P
  - NP분류(NP class)
    - NP : 비결정적 다항식 시간
      - Not P가 아님!!!, P와 NP는 반대적이나 이런게 아님
    - 비결정론적 튜링 기계
      - 어떤 명령어 실행 뒤, 다음 실행할 명령어가 확정되지 않음
      - 여러 개의 다음 명령어를 병렬적으로 실행하는 기계

<br/>

  - 결정론적 튜링 기계에서의 NP문제
    - 일단 답이 있으면 그 답이 맞는지를 다항식 시간안에 검증할 수 있음
    - 푸는 데는 지수 시간이 걸릴 수도 있음

<br/>

  - 랜덤 접근 기계는 결정론적 튜링 기계(요즘 컴퓨터도 이와 같다!)
    - 랜덤 접근 기계 : 레지스터를 갖춘 CPU1개
    - 결정론적 튜링 기계
      - 어떤 명령어 실행 즉시, 다음 실행할 명령어가 확정됨
      - 코어 하나에서 명령어를 순서대로 실행한다 생각할 것
    - 앞으로 별도 언급이 없으면 결정론적 튜링 기계를 의미
      - NP문제를 일반적인 방법으로 풀기에는 좀 느림

<br/>

  - P문제는 결정론적 튜링 기계에서 다항식 시간 안에 풀 수 있는 모든 문제를 포함
  - NP문제는
    - 비결정론적 튜링 기계에서 해법을 다항식 시간안에 찾을 수 있는것
    - 결정론적 튜링 기계에서 일단 답이 있으면 그 답이 맞는지를 다항식 시간안에 검증할 수 있음
    - P가 풀 수 있는문제이기 때문에는 P문제라면, NP문제라고 할 수 있다

<br/>

  - NP-완전(NP-complete, NPC) 문제
    - NP문제중 일부
    - 모든 NP문제들은 NP-완전 문제로 환원 가능
      - 그것도 다항식 시간 안에
      - 여전히 NP문제이니 다항식 시간안에 답 검증 가능
    - 최소 다른 NP문제들만큼 어려운 문제
    - 따라서 NP중에서도 가장 어려운 문제라고 할 수 있음
  - NP-난해(NP-hard) 문제
    - 최소 NP-완전 문제만큼 어려운 문제들
    - NP가 아닌 문제도 있음
      - 즉, 다항식 시간 안에 답 검증이 불가능한 문제
      - 당연히 NP보다 복잡도가 높은 문제

<br/>

  - P = NP vs P != NP
    - NP-완전 문제는 NP 문제 중 가장 어려운 문제
    - NP-완전 문제 중 하나라도 다항식 시간 안에 풀 수 있다면?
      - 이 문제는 P가 됨
      - 모든 NP문제를 NP-완전 문제로 다항식 시간 안에 환원할 수 있음
      - 따라서 모든 NP 문제가 P가 됨(P = NP)
    - P = NP가 되면 디지털 사회에 미치는 여파는?
      - 느려서 못 풀던 그 많은 문제를 효율적으로 풀 수 있음

###### [주먹구구식 알고리듬, P vs NP 문제](#주먹구구식-알고리듬-p-vs-np-문제)
###### [Top](#top)

<br/>
<br/>

***

# 탐색 알고리듬, 이진 탐색
  - 탐색 알고리듬
    - 어떤 데이터 구조 안에 저장되어 있는 정보를 구해오는 알고리듬
    - 매우 다양한 것이 여기에 포함됨
      - 배열에서 제일 큰 값 찾기
      - 데이터베이스에서 레코드 하나 읽어오기
      - 배낭 문제
      - 등
    - 대표적인 탐색 알고리듬
      - 선형(linear) 탐색 알고리듬 O(N)
      - 해시 맵을 이용한 탐색 O(1)
  - 이진 탐색 알고리듬
    - 정렬된 배열에서 어떤 값의 위치를 찾는 알고리듬
    - 한 단계 진행할 때마다 탐색범위를 절반으로 줄임
      - 이진 이라는 이름이 탄생한 이유
    - 분할 정복 알고리듬 중 하나
      - 정복이라 하기에는 모든 문제 영역을 방문하지 않음
    - 재귀 함수로 쉽게 작성 가능
  - 정렬된 데이터와 알고리듬
    - 정렬된 데이터에 사용할 수 있는 효율적인 알고리듬이 많음
    - 정렬되지 않은 배열은?
      - 정렬 알고리듬을 사용하여 정렬 가능
      - 일단 정렬하면 효율적 알고리듬 사용 가능
      - 하지만 배열에 새 요소를 추가하면 다시 정렬해야 함
        - 배보다 배꼽이 커질 수도 있음
       - 정렬 알고리듬이 이진 탐색보다 시간 복잡도가 높음
  - 정렬 후 이진 탐색 vs 선형 탐색
    - 배열이 안 바뀌고, 같은 배열을 탐색할 일이 많다면 정렬후 이진탐색으로
    - 배열이 자주 바뀌는 경우는 정렬 하지 않고 선형 탐색으로

<br/>

#ConsoleApp.cpp
~~~c++
#include <iostream>

// 이진 탐색
int binarySearch(int* arr, int start, int end, int target)
{
    if (start <= end)
    {
        int mid = start + (end - start) / 2;

        if (arr[mid] == target)
            return mid;
        else if (arr[mid] > target)
            return binarySearch(arr, start, mid - 1, target);
        else
            return binarySearch(arr, mid + 1, end, target);
    }

    return -1;
}

int main()
{
    int num[] = { 0,1,2,3,4,5,6,7,8,9,10 };

    int n = binarySearch(num, 0, 10, -1);
    std::cout << n << std::endl;
}
~~~

###### [탐색 알고리듬, 이진 탐색](#탐색-알고리듬-이진-탐색)
###### [Top](#top)

<br/>
<br/>

***

# 정렬 알고리듬(버블,선택,삽입,퀵,병합,힙)
  - 목록 안에 저장된 요소들을 특정한 순서대로 재배치하는 알고리듬
  - 정렬을 하는 이유
    - 좀 더 효율적인 알고리듬을 사용하기 위해
    - 사람이 읽기 편하도록
    - 등
  - 입력 데이터는 일반적으로 배열 같은 데이터 구조에 저장
    - 아무 위치로의 임의 접근을 허용
    - 연결 리스트를 사용하면 처음 혹은 끝부터 차례대로 훑어야 함
  - 흔히 사용하는 순서 : 숫자 순서, 사전 순서
  - 정렬 방향 : 오름차순, 내림차순
  - 다양한 정렬 알고리듬이 있음
    - 시간 복잡도 차이
    - 메모리 사용량 차이
    - 안정성 차이
      - 안전성(safety)이 아님!
      - 똑같은 키(key)를 가진 데이터들의 순서가 바뀌지 않느냐 여부
    - 직렬 vs 병렬 차이

<br/>

  - 안정성을 잘 모르는 이유
    - 같은 키를 가진 데이터의 순서가 바뀌어도 문제가 아닌 경우가 보통
    - 그래서 잘 모르고 생각도 안 하는 부분
    - 심지어는 이렇게 잘못 생각하기도 함
      - 모든 정렬 알고리듬은 같은 키를 가진 데이터의 순서를 안 바꾼다
    - 이 때문에 버그가 나도 못 고치는 경우가 있음
    - 진실
      - 어떤 정렬 알고리듬은 안정성을 보장
      - 어떤 정렬 알고리듬은 보장 안 함
  - 안정성이 문제가 되는 경우
    - 1. 정렬의 기준이 되는 정렬 키(sort key)와 실제 데이터가 다름
    - 2. 구조체/클래스의 일부 멤버만 정렬 키로 사용

<br/>

  - 대표적인 정렬 알고리듬
    - 버블 정렬
      - 언제라도 구현할 수 있어야 함
    - 선택 정렬
      - 언제라도 구현할 수 있어야 함
    - 퀵 정렬
      - 언제라도 설명할 수 있어야 함
    - 병합 정렬
      - 이해하는 정도면 충분
    - 힙 정렬
      - 이해하는 정도면 충분
    - 삽입 정렬
  - 정렬 알고리듬은 아무리 빨라도…
    - 배열을 비교/정렬하려면 모든 요소를 최소 한 번씩은 방문해야 함
    - 배열의 모든 요소를 방문하는 것은 O(N)
    - 따라서 정렬 알고리듬은 아무리 빨라도 O(N)보다 느림
    - 흔히 보는 시간 복잡도 중 O(N)다음으로 느린 것은? : NlogN
  - 정렬 알고리듬 비교
    - 퀵의 경우는 스택 메모리를 사용하기 때문에 메모리 할당과 해체가 공짜로 일어난다. 그래서 병합,힙 알고리듬보다 더 빠르다. 퀵은 거의 O(1)으로 돌아간다고 생각할 수 있다

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/d5c3a20f-c4aa-4648-8b3b-a8142471c479)

<br/>

  - 상황에 따른 정렬 알고리듬 선택
    - 기본적인 상황 : 퀵 정렬
      - C도 qsort()함수를 기본 제공
    - 간단히 구현할 때 : 버블 정렬
      - 구현이 매우 쉬움
      - 10년 안써도 까먹을 수 없을 정도
    - 어떤 경우에도 느려지면 안 될 때 : 병합 또는 힙 정렬
      - 평균은 퀵 정렬 보다 느림
      - 최악의 경우 여전히 O(N log N)
    - 특수한 상황에 적합한 정렬 알고리듬도 존재
      - 예 :  기수(radix)정렬

<br/>

  - 버블(bubble) 정렬
    - 가장 간단한 알고리듬 중 하나
      - 기본기 중의 기본기
      - 스스로 이 알고리듬을 고안하지 못해도 됨
      - 하지만 한 번 이해하면 언제라도 작성 가능해야 함
    - 이웃 요소 둘을 비교해서 올바른 순서로 고치는 과정을 반복
    - 한번 목록을 순회할 때마다 가장 큰 값이 제일 위로 올라가
      - 기포가 수면으로 떠오르는 모습을 닮았다고 해서 버블 정렬
      - 큰 기포일수록 수면으로 더 빨리 떠오름
    - 버블 정렬의 시간 복잡도
      - N - 1회(N : 요소 수)
    - 버블 정렬의 공간 복잡도
      - 새로 만든 목록이 없기 때문에 O(1)
    - 버블 정렬의 안정성
      - 값이 같은 경우 순서를 바꾸지 않음, 따라서 정렬 후에도 순서가 유지가 되기 때문에, 안정성 : O

<br/>

#ConsoleApp.cpp
~~~c++
#include <iostream>

int main()
{
    int array[] = { 10, 9, 8, 4, 5, 3, 7, 1, 2, 6 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	for (int i = 0; i < arraySize - 1; i++)
	{
		for (int j = 0; j < arraySize - i - 1; j++)
		{
			if (array[j] > array[j + 1])
			{
				int temp = array[j];
				array[j] = array[j + 1];
				array[j + 1] = temp;
			}
		}
	}

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 선택(selection) 정렬
    - 역시 가장 간단한 정렬 알고리듬 중 하나
    - 목록을 총 N-1번 훑으면서 다음 과정을 반복
      - 첫 번째는 요소0부터 훑으면서 최솟값을 찾아 요소 0과 교환
      - 두 번째는 요소1부터 훑으면서 최솟값을 찾아 요소 1과 교환
      - 세 번째는 요소2부터 훑으면서 최솟값을 찾아 요소 2과 교환
      - N-1 번째까지 반복…
    - 최솟값을 찾아 선택한다고 해서 선택 정렬
    - 시간/공간 복잡도 : 버블 정렬과 동일
    - 안정성 : 보장 안됨
      - 예) 같은 3이라는 숫자가 4번째 인덱스 7번째 인덱스에 있지만, 정렬을 하면서 7번째에 있는 인덱스 3숫자가 4번째 인덱스 보다 작은 인덱스로 이동하게 될 수도 있다

#ConsoleApp.cpp
~~~c++
#include <iostream>

int main()
{
	// 최소값으로 정렬하기
    int array[] = { 10, 9, 8, 4, 5, 3, 7, 1, 2, 6 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	int inMinIndex = 0;
	for (int i = 0; i < arraySize - 1; i++)
	{
		inMinIndex = i;

		for (int j = i + 1; j < arraySize; j++)
		{
			if (array[j] < array[inMinIndex])
			{
				inMinIndex = j;
			}
		}

		// 최소값과 현재 위치의 값을 교환
		int temp = array[i];
		array[i] = array[inMinIndex];
		array[inMinIndex] = temp;
	}

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 삽입(insertion)정렬
    - 역시 간단한 정렬 알고리듬 중 하나
    - 버블 정렬, 선택 정렬보다 구현은 아주 조금 힘듦
    - 목록을 차례대로 훑으로면서 다음 과정을 반복
      - 현재 위치의 요소를 뽑음
      - 이걸 과거에 방문했던 요소들 중에 어디 사이에 넣어야 정렬이 유지되는지 판단
      - 그 위치에 삽입
      - 삽입으로 인해 다른 요소들을 오른쪽으로 밀어야(shift) 할 수도 있음
    - 외부 반복문의 반복 횟수는 고정
      - 모든 요소를 방문함
      - 정해진 횟수기 때문에 for문이 적합
    - 내부 반복문의 반복 횟수는 가변적
      - 필요한 만큼까지만 오른쪽으로 미는 방식
      - 정해지지 않은 횟수이니 while문이 더 적합
    - 시간/공간 복잡도 : 버블 정렬과 동일
    - 안정성 : 보장 됨

#ConsoleApp.cpp
~~~c++
#include <iostream>

int main()
{
	// 최소값으로 정렬하기
    int array[] = { 10, 9, 8, 4, 5, 3, 7, 1, 2, 6 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	for (int i = 1; i < arraySize; i++)
	{
		int key = array[i];
		int j = i - 1;

		while (j >= 0 && array[j] > key)
		{
			int temp = array[j];
			array[j] = array[j + 1];
			array[j + 1] = temp;

			j--;
		}
	}

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 퀵(quick) 정렬
    - 실무에서 가장 많이 사용하는 정렬
      - 일반적/범용적으로 가장 빠름
    - 진정한 분할 정복 알고리듬
      - 모든 요소를 방문함
      - 복잡도에 log가 있다는 것에서 눈치챌 수 있음
    - 어떤 값(pivot)을 기준으로 목록을 하위 목록으로 2개로 나눔
      - 목록을 나누는 기준은 pivot보다 작냐/크냐
      - 이 과정을 재귀적으로 반복
      - 재귀 단계가 깊어질 때마다 새로운 pivot 값을 뽑음
    - 퀵 정렬의 시간 복잡도
      - 각 단계마다 방문하는 요소 수 : O(N)
      - 총 몇 개의 단계?
        - 매 단계에서 좌우가 균등하게 나뉘면
          - O(log N)
        - 매 단계 모든 요소가 한쪽으로 몰리면
          - O(N)
      - 평균 : O(N log N)
      - 최악 : O(N²)
    - 최악의 상황 피하기?
      - 제일 끝이 아닌 다른 위치를 기준값으로 뽑음
      - 기준값 위치의 예
        - 왼쪽
        - 오른쪽
        - (왼쪽 + 오른쪽) / 2
      - 어느 경우에도 최악의 상황은 있음
    - O(N²)을 절대로 허용할 수 없다면?
      - 다른 정렬을 사용할 것
      - 평균 속도 vs 최악의 상황 사이의 균형
    - 여러가지 분할법
      - 왼쪽-> 오른쪽 : 로무토 분할법
      - 왼쪽-> 오른쪽, 오른쪽 -> 왼쪽 번갈아 진행 : 호어 분할법
        - 어떤 값을 기준값으로 선택해도 잘 작동
        - 하지만 중간 값을 피벗으로 사용하면 더 빠르게 만들 수있다
    - 퀵 정렬의 공간 복잡도
      - 재귀적으로 함수를 호출
      - 실제 원본 배열을 고침 : O(1)
      - 함수 호출 깊이만큼 스택 메모리 사용
        - O(log N)
        - 스택 메모리라 할당/해제가 매우 빠름
      - 한 함수 내에서 재귀 함수를 두번 호출
       - 두 번째 호출은 꼬리 재귀를 통해 피할 수 있음

<br/>

#ConsoleApp.cpp
~~~c++
// 로무토 분할법
// 피봇값이 맨 오른쪽
#include <iostream>

void quicksort(int nums[], int left, int right)
{
	if (left >= right)
	{
		return;
	}

	int pivot = right;
	int basePoint = left;

	for (int i = left; i < right; i++)
	{
		if (nums[pivot] > nums[i])
		{
			int temp = nums[i];
			nums[i] = nums[basePoint];
			nums[basePoint] = temp;
			basePoint++;
		}
	}

	int temp = nums[pivot];
	nums[pivot] = nums[basePoint];
	nums[basePoint] = temp;
	pivot = basePoint;

	quicksort(nums, left, pivot - 1);
	quicksort(nums, pivot + 1, right);
}

void quickLomuto(int arr[], int size)
{
	quicksort(arr, 0, size - 1);
}


int main()
{
	// 최소값으로 정렬하기
    int array[] = { 6, 2, 8, 3, 1, 4, 9, 5, 7, 0 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	// 정렬하기
	quickLomuto(array, arraySize);

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

#ConsoleApp.cpp
~~~c++
//호어 분할법
// 피봇값이 맨 왼쪽
#include <iostream>

void quicksort(int arr[], int start, int end)
{
	if (start >= end)
		return;

	int pivot = start;
	int low = start + 1;
	int high = end;

	while (low <= high)
	{
		while (arr[pivot] >= arr[low] && low <= end)
		{
			low++;
		}

		while (arr[pivot] <= arr[high] && high >= (start + 1))
		{
			high--;
		}

		if (low < high)
		{
			int temp = arr[low];
			arr[low] = arr[high];
			arr[high] = temp;
		}
	}

	int temp2 = arr[high];
	arr[high] = arr[pivot];
	arr[pivot] = temp2;
	pivot = high;

	quicksort(arr, start, pivot - 1);
	quicksort(arr, pivot + 1, end);
}


void quickHoare(int arr[], int size)
{
	quicksort(arr, 0, size - 1);
}


int main()
{
	// 최소값으로 정렬하기
    int array[] = { 6, 2, 8, 3, 1, 4, 9, 5, 7, 0 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	// 정렬하기
	quickHoare(array, arraySize);

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

~~~c++
//호어 분할법
// 피봇값이 맨 왼쪽
// 피봇값이 중간값을 이용한 속도 개선
#include <iostream>

void quicksort(int arr[], int start, int end)
{
	if (start >= end)
		return;

	////////
	int samples[3] = { start, (start + end) / 2, end };

	if (arr[samples[0]] > arr[samples[1]])
	{
		int temp = samples[0];
		samples[0] = samples[1];
		samples[1] = temp;
	}
	if (arr[samples[1]] > arr[samples[2]]) {

		int temp = samples[1];
		samples[1] = samples[2];
		samples[2] = temp;
	}
	if (arr[samples[0]] > arr[samples[1]]) {

		int temp = samples[0];
		samples[0] = samples[1];
		samples[1] = temp;
	}

	int temp3 = arr[samples[1]];
	arr[samples[1]] = arr[start];
	arr[start] = temp3;
	////////

	int pivot = start;
	int low = start + 1;
	int high = end;

	while (low <= high)
	{
		while (arr[pivot] >= arr[low] && low <= end)
		{
			low++;
		}

		while (arr[pivot] <= arr[high] && high >= (start + 1))
		{
			high--;
		}

		if (low < high)
		{
			int temp = arr[low];
			arr[low] = arr[high];
			arr[high] = temp;
		}
	}

	int temp2 = arr[high];
	arr[high] = arr[pivot];
	arr[pivot] = temp2;
	pivot = high;

	quicksort(arr, start, pivot - 1);
	quicksort(arr, pivot + 1, end);
}

void quickHoare(int arr[], int size)
{
	quicksort(arr, 0, size - 1);
}

int main()
{
	int array[] = { 8, 2, 4, 1, 3, 10, 1, 1, 6, 5 };
	int arraySize = sizeof(array) / sizeof(array[0]);

	// 정렬하기
	quickHoare(array, arraySize);

	for (int i = 0; i < arraySize; i++)
	{
		// 콘솔에 출력하기
		std::cout << array[i] << " ";
	}
}
~~~

<br/>

  - 병합(merge)정렬
    - 1. 입력 배열을 재귀적으로 반씩 나눠 요소수가 1인 배열들을 만듦
      - 요소수가 1이니 정렬된 배열
      - 정확히 반씩 나누니 재귀 깊이는 O(log N)
    - 2. 재귀 반대 방향으로 배열을 계속 합침
      - 이때 정렬된 상태를 유지해야 함
      - 각 재귀 단계마다 방문하는 요소수는 O(N)
    - 3. 제일 상위 단계까지 합치면 정렬 끝

<br/>

  - 병합정렬 예제 추가하기

<br/>

  - 힙(heap) 정렬
    - 힙은 트리(tree)에 기반한 자료 구조
      - 우선순위 큐의 효율적인 구현 방법 중 하나
    - 힙 정렬은 힙이 사용하는 정렬 알고리듬
      - 언제나 부모의 키가 자식의 키와 같거나 큼
      - 이 자료구조에 데이터를 저장하는 순간 정렬이 됨
      - 즉, 정렬 안 된 데이터를 힙에 한 번 넣었다 빼면 끝
<br/>

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/dee80b15-187f-4ca6-841f-99569e9c4912)

  - 힙정렬 예제 추가하기

###### [정렬 알고리듬(버블,선택,삽입,퀵,병합,힙)](#정렬-알고리듬버블선택삽입퀵병합힙)
###### [Top](#top)

<br/>
<br/>

***

# 해시 알고리듬
  - 다양한 해시 알고리듬의 용도
    - 해시(hash)는 컴퓨터 공학에서 매우 근본이 되는 알고리듬 중 하나
      - 해시 테이블에서 데이터를 저장할 위치를 찾기 위해
      - 길이가 긴 데이터 둘을 빨리 비교하기 위해
      - 누출되면 곤란한 데이터의 원본을 저장하지 않기 위해
  - 해시 함수의 정의
    - 임의의 크기를 가진 값을 고정 크기의 값에 대응시키는 함수
      - 임의 크기 -> 고정크기가 된다
    - 여전히 함수이므로 수학에서의 함수의 정의도 만족해야 함
      - 어떤 입력값에 어떤 출력값이 나옴(출력 값이 2개가 나올수 없고, 입력값이 똑같은것이 들어가면 출력 값이 똑같은 것이 나온다)
  - 해시 알고리듬 분류
    - (비 암호학적) 해시 함수
      - 체크섬
      - 순환 중복 검사
      - 등
    - 암호학적 해시 함수

<br/>

  - 해시 알고리듬 속성
    - 효율성
    - 보통 빠른 해시 함수를 선호함
    - 공간을 더 낭비해도 빠른 접근 속도를 선호
    - 충돌이 좀 더 나더라도 더 빠른 함수를 선호
      - 충돌은 드문 일
      - 몇개 난다고 O(1)에서 크게 느려지지 않음
    - 하드웨어 가속이 어려운 해시를 선호하는 경우도 있음
      - 여전히 소프트웨어에서는 빨리 실행되는 걸 선호
    - 균일성
    - 해시 함수의 출력값이 고르게 분포될수록 균일성이 높음
    - 흔히 훌륭한 해시 함수는 균일성이 높아야 한다고 함
      - 출력 범위 안의 모든 값들이 동일한 확률로 나와야 함(균등 분포)
      - 이러면 해시 충돌이 적어 O(1)해시 테이블을 기대할 수 있음
    - 완벽한 해시 함수 : 해시 충돌이 전혀 없는 함수
      - 입력값이 매우 제한적일 경우에만 가능
    - 균일성의 측정
      - 카이제곱 검정을 이용
      - 결과가 0.95~1.05 사이면 균일한 분포를 가진 해시 함수라 봄
      - 해시 값이 덜 중복되게 버킷 수를 정하면 균일성을 높일 수 있음(소수를 사용)
      - 완벽한 눈사태가 나도록 해시 함수를 설계하면 균일성을 높일 수 있다
        - 눈사태 효과 : 입력값이 약간만 바뀌어도 출력값이 굉장히 많이 바뀌는것, 엄격한 눈사태 기준은 입력값에서 1비트를 뒤집으면 출력값의 각 비트가 뒤집힐 확률이 50%가 되는것
    - 균일성이 높다고 항상 좋은 것이 아니라 다 쓰임세가 있음
      - 비슷한 내용을 가진 데이터끼리 충돌하게 함
      - 엄청나게 많은 데이터에서 비슷한 것들을 찾는 용도

<br/>

  - 비암호학적 해시 함수
    - 암호학적으로 사용하기에 안전하지 않은 해시 함수들
    - 보안적으로 문제없는 용도에 주로 사용
      - 데이터 저장 및 찾기
      - 저장/전송 중에 생긴 데이터 오류 탐지
      - 고유한 ID 생성
      - 등
    - 절대 반지는 없다
      - 모든 데이터에 대해 최고의 결과를 보장하는 해시 함수는 존재하지 않음
      - 입력값에 따라 다른 해시 함수를 사용하는 확률적 알고리듬은 존재
        - 유니버설 해싱
      - 따라서 용도에 맞는 해시 함수를 사용하는 게 중요
      - 심지어는 비트 패킹도 해시 함수로 사용 가능
    - 체크섬(checksum)
      - 비암호학적 해시
      - 여러 데이터로부터 도출한 작은 크기의 데이터 하나
        - 보통 데이터에 있는 모든 바이트를 어떤 방식으로든 합함
      - 해시 함수랑 매우 비슷한 개념
        - 출력값의 크기가 고정되어 있으면 해시 함수
      - 용도 : 저장 혹은 전송 중에 발생한 오류를 찾아냄
        - 처음 데이터를 저장할 때 체크섬을 계산해 그것도 저장
        - 나중에 데이터를 읽을 때 다시 체크섬을 계산
        - 처음에 저장해둔 체크섬과 다르면 오류가 난것
      - 예시 : 주민등록 번호 유효성 검사
        - 존재할 수 있는 번호인지 검사
        - 마지막 숫자는 어떠한 공식에 따라서 계산하여 표기한다
        - 이러한 방법으로 체크섬을 사용한다
      - 예시 : 신용카드 번호의 유효성 검사
        - 총 16자리
        - 마지막 숫자를 룬 알고리듬으로 만듦
      - 체크섬 알고리듬은 매우 간단
        - 보통 간단한 산술 연산
        - 계산이 빠르고 추가 메모리가 거의 불필요
          - 네트워크 프로토콜에서 사용
          - 하드웨어로도 구현하기 쉬움
        - 단, 모든 오류를 찾지는 못함
      - 체크섬은 데이터가 바뀐지만 확인
        - 보통 복구는 신경 쓰지 않음
        - 따라서 체크섬이 일치하지 않으면, 데이트 전송의 경우는 재전송 요청
        - 저장 중인 데이터라면..날아감
        - 데이터 복구를 지원하는 것도 있음
    - 패리티 비트(parity bit)
      - 비암호학적 해시
      - 체크섬중 하나
      - 이진수로 저장된 데이터에 추가하는 1비트짜리 체크섬
      - 보통 1바이트 단위로 많이 사용(7비트 데이터 + 1비트 패리티)
      - 짝수 패리티와 홀수 패리티로 나뉨
        - 패리티까지 포함한 모든 비트를 더하면 그 결과가 짝수 또는 홀수가 되어야 함
      - ex) 데이터 : 000 0000 / 1비트 갯수 : 0 / 홀수패리티 : 1000 0000 / 짝수패리티 : 0000 0000
      - ex) 데이터 : 010 1100 / 1비트 갯수 : 3 / 홀수패리티 : 0010 1100 / 짝수패리티 : 1010 1100
      - ex) 데이터 : 111 1111 / 1비트 갯수 : 7 / 홀수패리티 : 0111 1111 / 짝수패리티 : 1111 1111
    - 순환중복 검사(cyclic redundancy check)
      - 비암호학적 해시
      - 체크섬중 하나
      - 다항식의 나머지 연산을 이용하여 검사값을 만듦
        - 검사값은 보통 고정된 길이
        - 따라서 CRC함수를 해시 함수로 사용하기도 함
      - 역시 이진수 하드웨어에서 구현하기 쉬움
        - 심지어 최신 CPU는 CRC-32C명령어를 탑재
      - 다항식의 최고차항에 따라 CRC에 사용하는 비트 수가 달라짐
        - 각 항의 계수는 1 아니면 0
        - 최고차항의 계수는 언제나 1
        - 예) x³ + x + 1 -> 1011(총4비트)
        - 최고차항은 언제나 1이기 때문에 -> 011 이렇게 표현할 수 있음
      - CRC알고리듬들
        - CRC-8
        - CRC-16
        - CRC-32
        - CRC-64

<br/>

  - 암호학적 해시 알고리듬
    - 해시값에서 원본 값을 찾는게 사실상 실행 불가능한 알고리듬
      - 일방향 함수
      - 수학적인 지식이 많이 요구되는 부분
      - 따라서 이미 있는 해시 함수를 주로 사용
    - 원본 값을 찾으려면 모든 조합을 모두 시도해봐야 함(무차별 대입 공격)
    - 보안 분야에서 다양한 용도로 사용
    - 예시
      - 메시지나 파일의 무결성 검사
      - 디지털 서명 생성 및 검증
      - 비밀번호 검증
      - 작업 증명
        - 블록체인 등에서 서비스 거부 공격을 어렵게 만들기 위해
      - 일반 해시 알고리듬 대신으로 사용 가능
    - 암호학적 해시 알고리듬의 예
      - MD5
      - SHA-1
      - SHA-256
      - SHA-512

<br/>

  - 암호학적 해시 알고리듬의 추가 속성
    - 역상 저항성(pre-image resistance)
      - 해시값으로부터 원본 데이터를 찾기가 어려워야 함
        - 원본 데이터를 같이 저장하지 않는 용도에 적합
      - 비보안학적 해시 함수에서 본 비트 패킹은 역상 저항성이 거의 없음
        - 낮은 역상 저항성을 이용하는 게 역상 공격
        - 무차별 대입 공격을 통해서만 해시값을 찾을 수 있는 것이 이상적
      - 즉, 해시 값으로 부터 패턴을 보기 어려워야 함
        - 해시값의 길이가 길수록 좋음
    - 제2 역상 저항성
      - 똑같은 해시값이 나오는 다른 입력값을 찾기 어려워야함
        - (입력값, 해시값) 쌍을 이미 가지고 있을 때
        - 이 저항성이 낮으면 제 2 역상 공격에 취약함
      - 역상 저항성 보다 한 가지 정보가 더 있는 경우
        - 역상 저항성은 해시값만 있음
        - 제 2역상 저항성은 입력값도 알고 있음
    - 충돌 저항성
      - 해시값이 똑같은 두 입력값을 찾기가 어려워야 함
        - 해시값도 입력값도 주어지지 않은 경우
        - 이 저항성이 낮으면 충돌 공격에 취약
      - 충돌 공격은 역상 공격들 보다 쉬움
        - 이미 MD5와 SHA-1에 대해 실행 가능한 충돌 공격이 발견됨
        - MD5는 일반 컴퓨터로 몇 초면 충분할 정도
        - 모든 암호학적 해시 함수는 생일 공격이 가능하기 때문
        - 생일 공격은 무차별 대입 공격보다 빠름
        - 생일문제
          - 회사직원 수는 20명, 이 중에 생일이 9월1일인 직원이 있을 확률은? : 5.3%(역상 공격과 비슷)
          - 회사직원 수는 20명, 그냥 생일이 겹치는 사람이 있을 확률은? : 41.1%(충돌 공격과 비슷)
        - 생일문제는 출력값의 길이가 정해져 있기에 생기는 문제임
          - 모든 암호학적 해시 함수가 생일 공격에 노출되어 있는 이유
        - 출력값의 길이를 늘리면 그 확률을 줄일 수 있음
          - 해시값의 크기가 클수록 좋은 이유

<br/>

  - 비밀번호를 해시로 저장해야 하는 이유
    - 웹사이트에서 모든 조합의 비밀번호를 시도하는 건 보호하지 않음
      - 해시값을 몰라도 DB와 비교해서 로그인 해주기 때문
      - 무차별 대입 공격은 여러 제약이 있음
        - 웹페이지 갱신 속도
        - 5번 실패 후, 계정 잠금 등
    - 데이터 베이스가 털렸을 때 비밀번호가 노출되는 걸 막음
      - 사람들은 같은 비밀번호를 여러 사이트에 사용
      - 각 사이트마다 다른 비밀번호를 사용해야 하는 이유
  - 해시에서 비밀번호를 찾는 법
    - 1. 해커의 컴퓨터에서 모든 조합의 비밀번호를 시도(무차별 대입 공격)
      - 웹에서 시도할 때의 제약을 받지 않음
      - 하드웨어 가속도 가능
        - 싸구려 그래픽 카드 하나로 초당 100억 개 이상의 MD-5를 계산할 수 있음
        - 영어 대소문자 8자리로 만들 수 있는 비밀번호는 약 534597억 개
        - 전부 시도하는데 걸리는 시간 1.5시간 미만
      - 하드웨어서만 효율성이 떨어지는 알고리듬을 선호
      - 비밀번호는 길수록 좋음
    - 2. 해커의 컴퓨터에서 사전에 있는 단어들로 시도(사전 공격)
      - 무차별 대입 공격과 기본은 같음
      - 하지만 사전에 있는 단어들을 조합해가며 시도
        - 사람들은 보통 기억하기 쉬운 단어를 비밀번호로 사용
        - 무차별 대입 공격보다 빠름
      - 비밀번호 생성기에서 생성한 뷁스러운 비밀번호가 더 나은 이유
    - 3. 해커가 가지고 있는 레인보우 테이블과 비교
      - 레인보우 테이블 : 미리 계산해 놓은 해시값의 목록
        - 흔히 사용하는 비밀번호들을 모두 계산한 결과를 저장
        - 흔히 사용하는 모든 해시 함수에 대해
      - 레인보우 테이블과 일치하는 해시값이 저장되어 있다면 찾는 시간은
        - 해시 테이블과 같음
        - O(1)
    - 1,2,3번 모두 시중에 알려져 있는 해시 함수를 사용해서 생기는 문제이다!
    - 하지만 독자적인 해시 함수를 사용하는것 또한 좋지 않다
  - 독자적인 해시 함수 사용이 안 좋은 이유
    - 보안업계에서 독자적인 암호학적 해시 함수 사용을 비추
      - 어떤 취약점이 있는지 알 수 없음
      - 보안감사를 제대로 하지 않음
      - 따라서 전문가들은 자체 암호화 기법을 사용하는 서비스를 피함
    - 공개적으로 검증된 해시 함수를 주로 사용
      - 초천재 수학자들과 보안전문가들이 개발 및 감사를 한 것들
      - 막강한 정부의 자금과 인력도 투입
      - 취약점이 발견되면 다 같이 털린다는 문제가 있음
      - 정부에 대한 음모론도 존재…
  - 비밀번호 덜 털리는 법
    - 1. 이미 털렸다고 알려진 비밀번호를 설정 못하게 한다
      - 대규모로 털린 비밀번호 목록을 웹에서 찾을 수 있음(API도 존재)
      - 그 비밀번호를 입력하면 다른 비밀번호를 만들라고 강제
    - 2. 긴 비밀번호를 사용하게 강제한다
      - 비밀번호의 자릿수가 늘어나면 시도해야 할 조합이 기하급수적으로 증가
    - 3. 아예 비밀번호를 저장하지 않는다
      - 이메일로 보낸 링크를 클릭하면 로그인이 되는 방법
      - 소셜 로그인만 받는 방법
    - 4. 비밀번호를 처음 저장할 때 랜덤 문자열도 같이 저장
      - 더 이상 레인보우 테이블에서 찾을 수 없음
      - 각 비밀번호마다 무차별 대입 공격 및 사전 공격을 해야 함
    - 5. 모든 비밀번호에 붙이는 공통된 문자열을 붙인다
      - 데이터 베이스에 저장하지 않고 웹 서비스에서만 알고 있는 값
        - 해커가 가지고 있지 않기에 거의 모든 공격을 무력화
        - 단, 데이터베이스 털릴 때, 웹 서버 메모리까지 털리면 도루묵..
    - 6. 업계에서 최고의 해시 함수라고 말하는 것을 선택할것
    - 7. 보안 관련 뉴스를 구독할 것
      - 해시 함수는 언제든 깨질 수 있음
      - 그러면 재빨리 더 나은 함수로 바꿔야 함
      - 해시 함수가 바뀌니 비밀번호를 다 리셋해야함
    - 8. 비밀번호 찾기를 허용하는 웹사이트를 조심할 것
      - 리셋이 아닌 찾기를 허용한다면 내 비밀번호가 저장되어 있다는 말

###### [해시 알고리듬](#해시-알고리듬)
###### [Top](#top)

<br/>
<br/>

***

# 암호화
  - 암호화(encryption)
    - 평문을 암호문으로 변환하는 것
      - 평문 : 누구나 읽으면 곧바로 이해할 수 있는 정보
      - 암호문 : 읽는다고 모두가 이해할 수는 없는 정보
    - 암호문도 누군가 훔쳐볼 수 있음
    - 단, 특별한 정보를 아는 사람만 이해할 수 있음
  - 복호화(decryption)
    - 암호문을 다시 평문으로 변환하는 것
    - 암호화에 사용한 방법을 알아야 빨리 복호화 가능
  - 해시 알고리듬은 원문 복구를 막는 게 목표
  - 암호화 알고리듬은 원문 복구를 허용해야 함

<br/>

  - 정수론(number theory)
    - 정수의 성질에 대해 연구하는 학문
    - 과거에는 실용적으로 써먹을 곳이 없었음
    - 2진수로 표현된 데이터를 암호화하려다 보니 갑자기 주목 받음
      - 결국 2진수도 정수이기 때문
    - 특히 소수에 관련된 정수론적 알고리듬이 많은 주목을 받음
      - 암호문의 패턴을 들키지 않으려면 겹치지 않는 수가 필요
      - 소수는 자연에서 가장 안 겹치는 수
  - 암호학에서 사용하는 정수
    - 매우 큰 정수
      - 흔히 사용하는 32비트 등의 정수가 아님
      - 32비트 범위 안에 있는 소수는 오직 203,280,220개 뿐
    - 입력 크기 N
      - 보통 배열 속의 요소 수를 의미
      - 암호학에서 사용하는 정수에서는 비트 수를 의미
    - 곱셈, 나눗셈, 나머지 연산의 시간 복잡도
      - 보통 정수는 O(1)
      - 암호학에서 사용하는 정수는 비트 수에 비례

<br/>

  - 스트림 암호 vs 블록 암호
    - 스트림 암호( stream cipher)
      - 한 번에 1바이트씩 받아 암호화를 진행
      - 안전하려면 각 바이트에 적용하는 키가 달라야 함
        - 보통 시드 값을 정하고 난수로 생성
      - 블록 암호보다 설정이 복잡하나 속도가 빠름
    - 블록 암호(block cipher)
      - 정해진 블록 크기(64비트 이상)만큼의 바이트를 한 번에 암호화
      - 각 블록에 사용하는 키가 동일함
      - 스트림 암호보다 설정이 간단하나 속도가 느림

<br/>

  - 현대에 사용하는 암호화 알고리듬 두 종류
    - 1. 대칭 키 암호화(symmetric-key encryption)
      - 암호화/복호화에 동일한 키 를 사용
    - 2. 비대칭 키 암호화(asymmetric-key encryption)
      - 공개 키 암호화(public-key encryption)라고도 함
      - 암호화와 복호화에 사용하는 키가 다름
  - 대칭 키 암호화
    - 암호화/복호화에 동일한 키를 사용
    - 이 키는 메시지 송신자와 수신자가 공유하는 비밀
      - 수신자가 이미 그 키를 가지고 있어야 복호화 가능
    - 송신자가 수신자에게 비밀스럽게 키를 알려줄 방법이 필요
      - 다른 사람들은 몰라야 비밀 유지가 됨
      - 대칭 키 암호화의 가장 큰 단점
    - Wi-Fi비밀번호도 일종의 대칭 키
      - 공유기에 설정하는 비밀번호와 스마트폰에 입력하는 키가 같음
      - 스마트폰과 공유기 사이에 통신할 때 이 키로 암호화를 함
      - WPA2-Personal은 이런 식으로 작동
        - 스마트폰이 처음 공유기에 접속 시 교환하는 어떤 값과 비밀번호를 합쳐 키 생성
        - 그 키를 이용해서 메시지를 암호화
        - 따라서 모든 접속자마다 다른 키를 사용
        - 하지만 해커가 둘 사이의 모든 트래픽을 캡쳐한다면 읽기 가능
          - 결국 키를 왔다 갔다 하는 순간이 있기 때문
    - 대칭 키 알고리듬 목록
      - DES, IDEA, Blowfish, AES, RC4, RC5, RC6, 등
  - AES
    - NSA에서 일급비밀 용으로 승인한 유일한 공개 암호화 알고리듬
    - 현재 가장 널리 사용되는 대칭 키 알고리듬
      - WPA2프로토콜의 일부로 사용되기도 함
    - 블록 크기 : 128비트
    - 키 길이 : 128, 192 또는 256비트
    - 키 길이에 따라 평문을 암호문으로 변환하는 라운드 수가 다름
      - 128비트 : 10라운드
      - 192비트 : 12라운드
      - 256비트 : 14라운드
    - AES는 한 번에 16바이트씩 읽어서 암호화
    - 평문의 원문을 16바이트  4 x 4행렬로 배치
    - 그 뒤 여러 처리 과정을 통해 암호화를 진행
    - AES 알고리듬의 구성
      - 1. 키 확장(key expansion)
        - 대칭 키로부터 각 라운드에 사용할 여러 키를 생성
          - 이를 라운드 키라고 부름
          - 생성법이 궁금하면 AES key schedule을 검색하기
        - 총 라운드 수 + 1 개의 라운드 키를 만듦
          - 즉, 각 라운드마다 다른 키를 사용
        - 대칭 키의 길이는 128/192/256 비트 중 하나
        - 그로부터 생성한 라운드 키는 모두 128비트
      - 2. 0라운드
        - a) 라운드 키 더하기
          - 더한다는 의미는 배타함(xor)
          - 평문의 원문의 16바이트 4 x 4행렬에 0라운드 키를 xor함
      - 3. 9/11/13 라운드
        - a) 0라운드에서 나온 행렬의 각 바이트를 다른 바이트로 대체함
          - AES S-Box라는 룩업 테이블을 사용함
          - 선형적인 변환이 아니기 때문에 단순 사칙 또는 비트 연산으로 찾을 수 없다(혼돈 효과를 성취)
        - b) 행 이동
          - 4개의 행을 각각 다르게 왼쪽으로 이동
            - 1행 : 이동 없음
            - 2행 : 1만큼
            - 3행 : 2만큼
            - 4행 : 3만큼
          - 확산 효과를 성취
        - c) 열 섞기
          - 각 열에 있는 4바이트를 선형적으로 변환
        - d) 라운드 키 더하기
      - 4. 최종 라운드 (총 라운드 수가 10/12/14 가됨)
        - a) 바이트 대체
        - b) 행 이동
        - c) 라운드 키 더하기
      - AES 알고리듬 나중에 더 자세히 알아보자!!

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/4f3e15f2-64a9-443e-a7cb-63c1daf175af)

<br/>

![image](https://github.com/BuMinKyoo/MY_ALL_INDEX/assets/39178978/90851ebc-43f6-4ce7-81f6-a21f79132ddc)

<br/>

  - 비대칭 키 암호화
    - 대칭 키 암호화는 훌륭한 기법이며 쓸 곳도 많음
      - 하드디스크에 파일을 암호화하여 저장
      - 데이터베이스에 고객 정보를 저장
      - 사내 서버 간 통신의 암호화
    - 하지만 암호화/복호화에 동일한 키를 사용해서 가끔 발목이 잡힘
      - 메시지 교환 용으로 사용할 때 안전하게 키를 배포하기가 힘듦
    - 보안 문제 없이 쉽게 키를 배포 할 수 있는 방법이 필요
    - 비대칭 키
      - 암호화와 복호화에 사용하는 키가 다름
      - 두 키 사이에는 특수한 수학적인 관계가 있음
        - 둘 중 한 키로 암호화한 메시지를 다른 키로 복호화할 수 있음
      - 따라서 키 하나는 완전히 공개해 놓아도 상관 없음
        - 이 키를 공개키(public key) 라고 부름
        - 비대칭 키 암호화를 공개 키 암호화라고도 부르는 이유도 이것 때문
      - 다른 키 하나는 한 개인이 비밀로 가지고 있음
        - 이 키를 비밀 키 또는 개인 키(private key) 라고 부름
  - 메시지 암호화
    - 송신자가 수신자의 공개 키로 원문 -> 암호문
      - 키가 공개돼 있으니 누구나 암호화 가능
      - 공개 키로는 암호문 -> 원문 변환 불가
    - 수신자는 자신의 비밀 키로 암호문 -> 원문 변환
      - 수신자만 알고 있는 키
      - 수산지만 원문을 볼 수 있음
  - 비대칭 키 암호화의 두 가지 주요 용도
    - 1. 전송하는 메시지의 암호화
      - 다른 사람이 원문을 못 보게 숨김
    - 2. 전자서명
      - 메시지는 누구든 볼 수 있음
      - 메시지 송신자가 올바름을 증명
      - 처음에 봤던 예
      - 암호화폐에서 돈을 옮길 때도 이 방법을 사용
      - 전자서명은 내가 가지고 있는 나의 비밀키로 암호화 해서 공개되어 있는 나의 은행창구에 보내고, 그곳에서 나의 공개키로 풀었을때 풀린다면 나라는 것은 인증하는 것이기 때문에 접근 가능하게 된다
  - 비대칭 키 암호화를 사용하는 곳
    - HTTPS
      - 비대칭 키 암호화와 더불어 대칭 키 암호화도 사용
    - 메신저 앱의 비밀 채팅 모드
      - 서버도 내 비밀 키를 모르는 모드
    - 비트코인 등의 암호화폐 프로토콜
    - Git 커밋의 전자서명
      - GitHub에서 지원하는 GPG키
  - 대표적인 비대칭 키 암호화 기법
    - 디피-헬만 키 교환
    - RSA
    - 디지털 서명 알고리듬
    - 타원곡선 DSA
  - 소수의 특징
    - 소수는 더 이상 인수분해가 안 되는 숫자
      - 1과 소수 그 자체로만 나눠짐
    - 서로 다른 두 소수  p, q를 곱하면 합성수 n이 나옴
    - n의 인수는 p와, q뿐
  - RSA
    - 현재 데이터 전송용으로 매우 널리 쓰이는 암호화 기법
    - 정수론에 기초해 놀라운 일들을 성취
    - 공개 키/비밀 키 쌍을 만드는 게 매우 쉬움
      - 매우 큰 두 소수를 이용
    - 이 두 키는 특수한 수학적 관계를 가짐
      - 공개 키를 알아도 그로부터 비밀 키를 찾기 매우 힘듦
      - 거듭제곱과 나머지 연산만으로 암호화 가능
      - 암호문을 다시 거듭제곱한 뒤, 나머지 연산을 하면 원문이 돌아옴
    - RSA가 이용하는 소수의 성질
      - 두 소수를 곱하는 것은 쉽게 할 수 있음
      - 두 소수를 곱한 합성수에서 그 소수들을 찾는 것은 훨씬 어려움
        - 이렇다 할 알고리듬이 없어 모든 조합을 곱해봐야 함
    - RSA 키 길이와 연산 속도
      - NIST에서 권하는 RSA의 키 길이
        - 2002년 : 1024비트
        - 2015년 : 2048비트
      - RSA-2048은 1024 비트 소수를 2개 사용
        - 즉, 308자리 숫자
      - 혹시라도 컴퓨터 속도가 더 빨라지면 비트 수를 늘리면 됨
    - RSA 공개 키/비밀 키의 기초
      - 비밀키 : 아주 큰 소수 p,q
        - p, q자체가 비밀키는 아니며, 비밀키의 일부이다
      - 공개키 : 합성수 n (n = p x q)
        - n 자체가 공개키는 아니며 공개키의 일부이다
      - p, q를 모르면 n으로부터 p, q를 찾기가 매우 힘듦
        - 즉, 공개 키로부터 비밀 키를 찾기가 매우 힘듦
        - 이것이 RSA공개 키/비밀 키 간의 첫 번째 특수한 관계
      - p, q와 특수한, 그리고 서로 간에도 특수한 관계인 e와 d를 찾음
        - e : 공개 키의 두 번째 요소가 됨
        - d : 비밀 키의 두 번째 요소가 됨
      - e와 d또한 특수한 관계를 만족해야 함
        - 나중에 검색해보기

<br/>

  - RSA키 생성
    - 1. 매우 큰 두 소수 p와 q를 찾는다
      - a. 매우 큰 랜덤 수를 뽑는다
      - b. 그 수가 소수인지 판별한다
      - c. 소수가 아니라고 판별되면 1번 단계로 돌아간다
      - d. 서로 다른 두 소수를 찾을 때까지 이 과정을 반복한다
      - ex) p = 57, q = 53
    - p와 q를 곱해 n을 만든다
      - n = 67 x 53 = 3551
    - p, q와 특수한 수학적 관계인 e를 찾는다
      - 1. n의 카마이클 수를 구한다 = 1716
      - 2, 이것에서 다른 찾는 방법을 통해서 e값을 찾아낸다(나중에 자세하게 공부해보자)
    - e와 특수한 수학적 관계인 d를 찾는다
      - 확장 유클리드 호제법을 사용하면 쉽게 찾을 수 있음
  - RSA를 이용한 암호화
    - 원문에 e승을 한후 n으로 나머지 연산을 한 나머지가 암호문이 된다
  - RSA를 이용한 복호화
    - 암호문에 d승을 한후 n으로 나머지 연산을 한 나머지가 원문이 된다
  - RSA를 증명하기..
    - 나중에 더 자세히 공부해보자..
  - 증명 과정에서 본 정리들
    - 정수의 성질을 공부하는 정수론에 속함
    - 실용성이 없다 여기던 학문을 암호학에 적용해 불가능한 일을 성취
    - 우리가 수학자들을 존경해야 하는 이유..

<br/>

  - 대칭 키 vs 비대칭 키 암호화의 속도
    - 비대칭 키 암호화가 보통 더 느림
      - 키의 길이가 훨씬 김(매우 큰 수로 하는 연산)
      - 알고리듬 자체가 더 복잡
      - 위 두 가지 이유는 결국 하나의 키를 공개하기 때문
    - 그래서 비대칭/대칭 키 암호화를 같이 사용하기도 함
      - 예) 세션동안 사용할 대칭 키를 비대칭 키 암호화를 이용해 전송

###### [암호화](#암호화)
###### [Top](#top)

<br/>
<br/>

***

# 트리


###### [트리](#트리)
###### [Top](#top)

<br/>
<br/>

***

# 이진 탐색 트리


###### [이진 탐색 트리](#이진-탐색-트리)
###### [Top](#top)

<br/>
<br/>

***

# 트리 순회(tree traversal)


###### [트리 순회(tree traversal)](#트리-순회tree-traversal)
###### [Top](#top)

<br/>
<br/>

***

# 레드-블랙 트리(red-black tree)


###### [레드-블랙 트리(red-black tree)](#레드블랙-트리redblack-tree)
###### [Top](#top)

<br/>
<br/>

***

# 트라이(Trie), 공간분할 트리


###### [트라이(Trie), 공간분할 트리](#트라이trie-공간분할-트리)
###### [Top](#top)

<br/>
<br/>

***

# 깊이 우선 탐색, 너비 우선 탐색, 미니맥스


###### [깊이 우선 탐색, 너비 우선 탐색, 미니맥스](#깊이-우선-탐색-너비-우선-탐색-미니맥스)
###### [Top](#top)

<br/>
<br/>

***

# 동적 계획법


###### [동적 계획법](#동적-계획법)
###### [Top](#top)

<br/>
<br/>

***

# 그리디(greedy, 탐욕) 알고리듬


###### [그리디(greedy, 탐욕) 알고리듬](#그리디greedy-탐욕-알고리듬)
###### [Top](#top)

<br/>
<br/>

***

# 그래프


###### [그래프](#그래프)
###### [Top](#top)

<br/>
<br/>

***

# 그래프 깊이 우선 탐색(DFS)


###### [그래프 깊이 우선 탐색(DFS)](#그래프-깊이-우선-탐색dfs)
###### [Top](#top)

<br/>
<br/>

***

# 그래프 너비우선 탐색(BFS), 최단경로


###### [그래프 너비우선 탐색(BFS), 최단경로](#그래프-너비우선-탐색bfs-최단경로)
###### [Top](#top)

***

# 그래프 알고리즘 다른것들


###### [그래프 알고리즘 다른것들](#그래프-알고리즘-다른것들)
###### [Top](#top)

<br/>
<br/>


















